{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import zscore\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from keras.datasets import cifar10\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "# Encode text values to a single dummy variable.  The new columns (which do not replace the old) will have a 1\n",
    "# at every location where the original column (name) matches each of the target_values.  One column is added for\n",
    "# each target value.\n",
    "def encode_text_single_dummy(df, name, target_values):\n",
    "    for tv in target_values:\n",
    "        l = list(df[name].astype(str))\n",
    "        l = [1 if str(x) == str(tv) else 0 for x in l]\n",
    "        name2 = \"{}-{}\".format(name, tv)\n",
    "        df[name2] = l\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, collections.Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "\n",
    "# Plot a confusion matrix.\n",
    "# cm is the confusion matrix, names are the names of the classes.\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "# Plot an ROC. pred - the predictions, y - the expected output.\n",
    "def plot_roc(pred,y):\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import color, exposure, transform\n",
    "\n",
    "NUM_CLASSES = 26\n",
    "IMG_SIZE = 200\n",
    "\n",
    "\n",
    "def preprocess_img_hsv(img):\n",
    "    # Histogram normalization in v channel\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:, :, 2] = exposure.equalize_hist(hsv[:, :, 2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central square crop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0] // 2, img.shape[1] // 2\n",
    "    img = img[centre[0] - min_side // 2:centre[0] + min_side // 2,\n",
    "              centre[1] - min_side // 2:centre[1] + min_side // 2,\n",
    "              :]\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "    img = np.rollaxis(img, -1)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "def preprocessing_img_black_and_white(img):\n",
    "    im_ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n",
    "    skin_ycrcb_mint = np.array((0, 133, 77))\n",
    "    skin_ycrcb_maxt = np.array((255, 173, 127))\n",
    "    skin_ycrcb = cv2.inRange(im_ycrcb, skin_ycrcb_mint, skin_ycrcb_maxt)\n",
    "    return skin_ycrcb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1300\n",
      "260\n",
      "1300\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "testFiles=[]\n",
    "trainFiles=[]\n",
    "for root, dirs, files in os.walk('./data/asl-alphabet/asl_alphabet_train/'):\n",
    "     for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                if not file.endswith('_test.jpg'):\n",
    "                    number=file[1:file.find('.')]\n",
    "                    if not number.isdigit():\n",
    "                        continue\n",
    "                    if(int(number)>50):\n",
    "                        continue\n",
    "                file_path = os.path.join(root,file)\n",
    "                #print(file_path)\n",
    "                if file.endswith('_test.jpg'):\n",
    "                    if (not file.startswith('nothing_') and not file.startswith('space_') and not(file.startswith('del_'))):\n",
    "                        testFiles.append(file_path)\n",
    "                else:\n",
    "                    if ((not \"nothing\" in file) and (not \"space\" in file) and (not \"del\" in file)):\n",
    "                        trainFiles.append(file_path)\n",
    "testFiles.sort()\n",
    "trainFiles.sort()\n",
    "print(len(testFiles))\n",
    "print(len(trainFiles))\n",
    "\n",
    "#creating the sample set of 20 test images for each alphabet\n",
    "import os\n",
    "\n",
    "testFiles=[]\n",
    "\n",
    "for root, dirs, files in os.walk('./data/asl-alphabet/asl_alphabet_train/'): #asl_alphabet_test_sample\n",
    "     for file in files:\n",
    "            if file.endswith('.jpg'):\n",
    "                if not file.endswith('_test.jpg'):\n",
    "                    number=file[1:file.find('.')]\n",
    "                    if not number.isdigit():\n",
    "                        continue\n",
    "                    if((int(number)<=50) or int(number)>60):\n",
    "                        continue\n",
    "                file_path = os.path.join(root,file)\n",
    "                #print(file_path)\n",
    "                if (not file.startswith('nothing_') and not file.startswith('space_') and not(file.startswith('del_'))):\n",
    "                    testFiles.append(file_path)\n",
    "                    \n",
    "testFiles.sort()\n",
    "trainFiles.sort()\n",
    "print(len(testFiles))\n",
    "print(len(trainFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300\n",
      "1300\n",
      "[[  0.   0.   0. ...   0.   0.   0.]\n",
      " [  0.   0.   0. ...   0.   0.   0.]\n",
      " [  0.   0. 255. ... 255.   0.   0.]\n",
      " ...\n",
      " [  0.   0. 255. ...   0. 255.   0.]\n",
      " [  0.   0.   0. ... 255.   0.   0.]\n",
      " [  0.   0.   0. ...   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "from skimage import io\n",
    "import numpy as np\n",
    "j=0\n",
    "# numpy_array_train = np.empty([78000,200,200,3])\n",
    "x_train = np.empty([1300,200,200])\n",
    "y_train = []\n",
    "y_train_for_df = []\n",
    "alphabet_array = []\n",
    "alphabet_array.append('A')\n",
    "alphabet_array.append('B')\n",
    "alphabet_array.append('C')\n",
    "alphabet_array.append('D')\n",
    "alphabet_array.append('E')\n",
    "alphabet_array.append('F')\n",
    "alphabet_array.append('G')\n",
    "alphabet_array.append('H')\n",
    "alphabet_array.append('I')\n",
    "alphabet_array.append('J')\n",
    "alphabet_array.append('K')\n",
    "alphabet_array.append('L')\n",
    "alphabet_array.append('M')\n",
    "alphabet_array.append('N')\n",
    "alphabet_array.append('O')\n",
    "alphabet_array.append('P')\n",
    "alphabet_array.append('Q')\n",
    "alphabet_array.append('R')\n",
    "alphabet_array.append('S')\n",
    "alphabet_array.append('T')\n",
    "alphabet_array.append('U')\n",
    "alphabet_array.append('V')\n",
    "alphabet_array.append('W')\n",
    "alphabet_array.append('X')\n",
    "alphabet_array.append('Y')\n",
    "alphabet_array.append('Z')\n",
    "k=0\n",
    "print(len(trainFiles))\n",
    "for i in trainFiles:    \n",
    "    x_train[j]=preprocessing_img_black_and_white(io.imread(i))\n",
    "    j=j+1\n",
    "    y_train.append(alphabet_array[k])\n",
    "    if (j%50) == 0: #j%3000 for complete\n",
    "        k=k+1\n",
    "\n",
    "print(len(x_train))\n",
    "print(x_train[1299])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 200, 200)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from skimage import io\n",
    "import numpy as np\n",
    "j=0\n",
    "k=0\n",
    "y_test = []\n",
    "x_test = np.empty([260,200,200]) \n",
    "\n",
    "for i in testFiles:    \n",
    "    x_test[j]=preprocessing_img_black_and_white(io.imread(i))\n",
    "    j=j+1\n",
    "    y_test.append(alphabet_array[k])\n",
    "    if (j%10) == 0:\n",
    "        k=k+1\n",
    "\n",
    "\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 200, 200)\n",
      "(260, 200, 200)\n",
      "(1300,)\n",
      "(260,)\n"
     ]
    }
   ],
   "source": [
    "y_train_np=np.asarray(y_train)\n",
    "y_test_np = np.asarray(y_test)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train_np.shape)\n",
    "print(y_test_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "print(x_train.dtype)\n",
    "print(x_test.dtype)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data values to the range [0, 1]\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Label Encoding\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train_np)\n",
    "df_y_train = pd.DataFrame(y_train, columns=['one_hot_encoded'])\n",
    "encode_text_dummy(df_y_train, 'one_hot_encoded')\n",
    "y_train = df_y_train.values\n",
    "\n",
    "\n",
    "y_test = le.fit_transform(y_test_np)\n",
    "df_y_test = pd.DataFrame(y_test, columns=['one_hot_encoded'])\n",
    "encode_text_dummy(df_y_test, 'one_hot_encoded')\n",
    "y_test = df_y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>LSTM</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 1300 samples, validate on 260 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 3.2816 - acc: 0.0292 - val_loss: 3.2641 - val_acc: 0.0385\n",
      "Epoch 2/100\n",
      " - 7s - loss: 3.2649 - acc: 0.0354 - val_loss: 3.2574 - val_acc: 0.0385\n",
      "Epoch 3/100\n",
      " - 7s - loss: 3.2532 - acc: 0.0415 - val_loss: 3.2452 - val_acc: 0.0538\n",
      "Epoch 4/100\n",
      " - 8s - loss: 3.2336 - acc: 0.0554 - val_loss: 3.2218 - val_acc: 0.0654\n",
      "Epoch 5/100\n",
      " - 8s - loss: 3.1958 - acc: 0.0877 - val_loss: 3.1895 - val_acc: 0.0615\n",
      "Epoch 6/100\n",
      " - 8s - loss: 3.1493 - acc: 0.1169 - val_loss: 3.1530 - val_acc: 0.0692\n",
      "Epoch 7/100\n",
      " - 8s - loss: 3.1032 - acc: 0.1162 - val_loss: 3.1089 - val_acc: 0.0846\n",
      "Epoch 8/100\n",
      " - 7s - loss: 3.0583 - acc: 0.1285 - val_loss: 3.0614 - val_acc: 0.1000\n",
      "Epoch 9/100\n",
      " - 7s - loss: 3.0110 - acc: 0.1208 - val_loss: 3.0230 - val_acc: 0.1038\n",
      "Epoch 10/100\n",
      " - 7s - loss: 2.9645 - acc: 0.1146 - val_loss: 2.9785 - val_acc: 0.0962\n",
      "Epoch 11/100\n",
      " - 7s - loss: 2.9061 - acc: 0.1285 - val_loss: 2.9084 - val_acc: 0.1154\n",
      "Epoch 12/100\n",
      " - 7s - loss: 2.8447 - acc: 0.1385 - val_loss: 2.8684 - val_acc: 0.1846\n",
      "Epoch 13/100\n",
      " - 7s - loss: 2.7771 - acc: 0.1600 - val_loss: 2.8032 - val_acc: 0.2269\n",
      "Epoch 14/100\n",
      " - 7s - loss: 2.7104 - acc: 0.1831 - val_loss: 2.7397 - val_acc: 0.2077\n",
      "Epoch 15/100\n",
      " - 7s - loss: 2.6474 - acc: 0.1969 - val_loss: 2.6935 - val_acc: 0.1923\n",
      "Epoch 16/100\n",
      " - 7s - loss: 2.5933 - acc: 0.2131 - val_loss: 2.6577 - val_acc: 0.1846\n",
      "Epoch 17/100\n",
      " - 7s - loss: 2.5397 - acc: 0.2315 - val_loss: 2.6027 - val_acc: 0.2577\n",
      "Epoch 18/100\n",
      " - 7s - loss: 2.4796 - acc: 0.2554 - val_loss: 2.5627 - val_acc: 0.2500\n",
      "Epoch 19/100\n",
      " - 7s - loss: 2.4242 - acc: 0.2577 - val_loss: 2.5129 - val_acc: 0.2269\n",
      "Epoch 20/100\n",
      " - 7s - loss: 2.3736 - acc: 0.2915 - val_loss: 2.4985 - val_acc: 0.2731\n",
      "Epoch 21/100\n",
      " - 7s - loss: 2.3135 - acc: 0.3085 - val_loss: 2.4401 - val_acc: 0.3000\n",
      "Epoch 22/100\n",
      " - 7s - loss: 2.2577 - acc: 0.3085 - val_loss: 2.4169 - val_acc: 0.2923\n",
      "Epoch 23/100\n",
      " - 7s - loss: 2.1957 - acc: 0.3346 - val_loss: 2.3302 - val_acc: 0.2962\n",
      "Epoch 24/100\n",
      " - 7s - loss: 2.1346 - acc: 0.3785 - val_loss: 2.3378 - val_acc: 0.3115\n",
      "Epoch 25/100\n",
      " - 7s - loss: 2.0910 - acc: 0.3700 - val_loss: 2.2347 - val_acc: 0.3846\n",
      "Epoch 26/100\n",
      " - 7s - loss: 2.0350 - acc: 0.3977 - val_loss: 2.2356 - val_acc: 0.3154\n",
      "Epoch 27/100\n",
      " - 7s - loss: 1.9873 - acc: 0.3977 - val_loss: 2.1464 - val_acc: 0.4000\n",
      "Epoch 28/100\n",
      " - 7s - loss: 1.9373 - acc: 0.4154 - val_loss: 2.1746 - val_acc: 0.3462\n",
      "Epoch 29/100\n",
      " - 7s - loss: 1.8867 - acc: 0.4338 - val_loss: 2.0936 - val_acc: 0.4038\n",
      "Epoch 30/100\n",
      " - 7s - loss: 1.8411 - acc: 0.4615 - val_loss: 2.0998 - val_acc: 0.3923\n",
      "Epoch 31/100\n",
      " - 7s - loss: 1.7963 - acc: 0.4685 - val_loss: 2.0052 - val_acc: 0.3962\n",
      "Epoch 32/100\n",
      " - 7s - loss: 1.7624 - acc: 0.4792 - val_loss: 2.0327 - val_acc: 0.4115\n",
      "Epoch 33/100\n",
      " - 7s - loss: 1.7134 - acc: 0.4892 - val_loss: 2.0184 - val_acc: 0.4577\n",
      "Epoch 34/100\n",
      " - 7s - loss: 1.6824 - acc: 0.5146 - val_loss: 1.9994 - val_acc: 0.4385\n",
      "Epoch 35/100\n",
      " - 7s - loss: 1.6390 - acc: 0.5146 - val_loss: 1.9874 - val_acc: 0.4077\n",
      "Epoch 36/100\n",
      " - 8s - loss: 1.6080 - acc: 0.5115 - val_loss: 1.9547 - val_acc: 0.4154\n",
      "Epoch 37/100\n",
      " - 7s - loss: 1.5622 - acc: 0.5669 - val_loss: 1.8831 - val_acc: 0.4538\n",
      "Epoch 38/100\n",
      " - 7s - loss: 1.5350 - acc: 0.5600 - val_loss: 1.8420 - val_acc: 0.4846\n",
      "Epoch 39/100\n",
      " - 7s - loss: 1.4926 - acc: 0.5808 - val_loss: 1.8465 - val_acc: 0.4808\n",
      "Epoch 40/100\n",
      " - 7s - loss: 1.4581 - acc: 0.5969 - val_loss: 1.8293 - val_acc: 0.4846\n",
      "Epoch 41/100\n",
      " - 7s - loss: 1.4123 - acc: 0.6215 - val_loss: 1.8769 - val_acc: 0.4615\n",
      "Epoch 42/100\n",
      " - 7s - loss: 1.3917 - acc: 0.6254 - val_loss: 1.7932 - val_acc: 0.5346\n",
      "Epoch 43/100\n",
      " - 8s - loss: 1.3458 - acc: 0.6400 - val_loss: 1.7860 - val_acc: 0.4923\n",
      "Epoch 44/100\n",
      " - 8s - loss: 1.3112 - acc: 0.6438 - val_loss: 1.7120 - val_acc: 0.5308\n",
      "Epoch 45/100\n",
      " - 7s - loss: 1.2871 - acc: 0.6346 - val_loss: 1.7336 - val_acc: 0.5077\n",
      "Epoch 46/100\n",
      " - 7s - loss: 1.2364 - acc: 0.6823 - val_loss: 1.7092 - val_acc: 0.5346\n",
      "Epoch 47/100\n",
      " - 7s - loss: 1.2008 - acc: 0.6823 - val_loss: 1.6938 - val_acc: 0.5577\n",
      "Epoch 48/100\n",
      " - 7s - loss: 1.1682 - acc: 0.7131 - val_loss: 1.6219 - val_acc: 0.5385\n",
      "Epoch 49/100\n",
      " - 7s - loss: 1.1401 - acc: 0.7092 - val_loss: 1.6159 - val_acc: 0.5231\n",
      "Epoch 50/100\n",
      " - 7s - loss: 1.0977 - acc: 0.7215 - val_loss: 1.5795 - val_acc: 0.5885\n",
      "Epoch 51/100\n",
      " - 7s - loss: 1.0667 - acc: 0.7369 - val_loss: 1.6056 - val_acc: 0.5731\n",
      "Epoch 52/100\n",
      " - 7s - loss: 1.0354 - acc: 0.7492 - val_loss: 1.6073 - val_acc: 0.5615\n",
      "Epoch 53/100\n",
      " - 7s - loss: 1.0103 - acc: 0.7546 - val_loss: 1.5573 - val_acc: 0.5577\n",
      "Epoch 54/100\n",
      " - 7s - loss: 0.9680 - acc: 0.7792 - val_loss: 1.5209 - val_acc: 0.5692\n",
      "Epoch 55/100\n",
      " - 7s - loss: 0.9378 - acc: 0.7800 - val_loss: 1.5231 - val_acc: 0.6154\n",
      "Epoch 56/100\n",
      " - 8s - loss: 0.9110 - acc: 0.7946 - val_loss: 1.5646 - val_acc: 0.5846\n",
      "Epoch 57/100\n",
      " - 8s - loss: 0.8895 - acc: 0.7938 - val_loss: 1.5220 - val_acc: 0.5731\n",
      "Epoch 58/100\n",
      " - 8s - loss: 0.8622 - acc: 0.8000 - val_loss: 1.4765 - val_acc: 0.6115\n",
      "Epoch 59/100\n",
      " - 7s - loss: 0.8207 - acc: 0.8246 - val_loss: 1.4473 - val_acc: 0.5846\n",
      "Epoch 60/100\n",
      " - 7s - loss: 0.7853 - acc: 0.8262 - val_loss: 1.3835 - val_acc: 0.6462\n",
      "Epoch 61/100\n",
      " - 7s - loss: 0.7538 - acc: 0.8477 - val_loss: 1.4138 - val_acc: 0.6308\n",
      "Epoch 62/100\n",
      " - 7s - loss: 0.7376 - acc: 0.8408 - val_loss: 1.5070 - val_acc: 0.5769\n",
      "Epoch 63/100\n",
      " - 7s - loss: 0.7071 - acc: 0.8446 - val_loss: 1.4195 - val_acc: 0.6269\n",
      "Epoch 64/100\n",
      " - 7s - loss: 0.6746 - acc: 0.8631 - val_loss: 1.3706 - val_acc: 0.6654\n",
      "Epoch 65/100\n",
      " - 7s - loss: 0.6538 - acc: 0.8769 - val_loss: 1.3747 - val_acc: 0.6346\n",
      "Epoch 66/100\n",
      " - 7s - loss: 0.6241 - acc: 0.8815 - val_loss: 1.3620 - val_acc: 0.6462\n",
      "Epoch 67/100\n",
      " - 7s - loss: 0.5978 - acc: 0.8777 - val_loss: 1.3783 - val_acc: 0.6654\n",
      "Epoch 68/100\n",
      " - 7s - loss: 0.5867 - acc: 0.8869 - val_loss: 1.3776 - val_acc: 0.6000\n",
      "Epoch 69/100\n",
      " - 7s - loss: 0.5563 - acc: 0.9015 - val_loss: 1.5034 - val_acc: 0.6038\n",
      "Epoch 70/100\n",
      " - 7s - loss: 0.5463 - acc: 0.9008 - val_loss: 1.4007 - val_acc: 0.6462\n",
      "Epoch 71/100\n",
      " - 7s - loss: 0.5159 - acc: 0.9208 - val_loss: 1.3597 - val_acc: 0.6538\n",
      "Epoch 72/100\n",
      " - 7s - loss: 0.4981 - acc: 0.9169 - val_loss: 1.3569 - val_acc: 0.6538\n",
      "Epoch 73/100\n",
      " - 7s - loss: 0.4817 - acc: 0.9185 - val_loss: 1.3369 - val_acc: 0.6846\n",
      "Epoch 74/100\n",
      " - 7s - loss: 0.4528 - acc: 0.9354 - val_loss: 1.2695 - val_acc: 0.6731\n",
      "Epoch 75/100\n",
      " - 7s - loss: 0.4279 - acc: 0.9392 - val_loss: 1.2797 - val_acc: 0.7038\n",
      "Epoch 76/100\n",
      " - 7s - loss: 0.4202 - acc: 0.9515 - val_loss: 1.3953 - val_acc: 0.6615\n",
      "Epoch 77/100\n",
      " - 7s - loss: 0.4026 - acc: 0.9438 - val_loss: 1.3325 - val_acc: 0.6846\n",
      "Epoch 78/100\n",
      " - 7s - loss: 0.3988 - acc: 0.9500 - val_loss: 1.3538 - val_acc: 0.6769\n",
      "Epoch 79/100\n",
      " - 7s - loss: 0.3778 - acc: 0.9500 - val_loss: 1.3254 - val_acc: 0.7115\n",
      "Epoch 00079: early stopping\n",
      "1\n",
      "Train on 1300 samples, validate on 260 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 3.2706 - acc: 0.0331 - val_loss: 3.2594 - val_acc: 0.0385\n",
      "Epoch 2/100\n",
      " - 7s - loss: 3.2576 - acc: 0.0369 - val_loss: 3.2528 - val_acc: 0.0385\n",
      "Epoch 3/100\n",
      " - 8s - loss: 3.2434 - acc: 0.0492 - val_loss: 3.2351 - val_acc: 0.0654\n",
      "Epoch 4/100\n",
      " - 7s - loss: 3.2140 - acc: 0.0846 - val_loss: 3.2130 - val_acc: 0.0500\n",
      "Epoch 5/100\n",
      " - 7s - loss: 3.1784 - acc: 0.1062 - val_loss: 3.1779 - val_acc: 0.0923\n",
      "Epoch 6/100\n",
      " - 8s - loss: 3.1404 - acc: 0.1354 - val_loss: 3.1388 - val_acc: 0.1731\n",
      "Epoch 7/100\n",
      " - 7s - loss: 3.0967 - acc: 0.1415 - val_loss: 3.0930 - val_acc: 0.1115\n",
      "Epoch 8/100\n",
      " - 8s - loss: 3.0473 - acc: 0.1462 - val_loss: 3.0506 - val_acc: 0.1769\n",
      "Epoch 9/100\n",
      " - 8s - loss: 2.9977 - acc: 0.1546 - val_loss: 3.0020 - val_acc: 0.2077\n",
      "Epoch 10/100\n",
      " - 8s - loss: 2.9331 - acc: 0.2092 - val_loss: 2.9119 - val_acc: 0.1615\n",
      "Epoch 11/100\n",
      " - 7s - loss: 2.8563 - acc: 0.1838 - val_loss: 2.8402 - val_acc: 0.1962\n",
      "Epoch 12/100\n",
      " - 8s - loss: 2.7727 - acc: 0.2300 - val_loss: 2.7555 - val_acc: 0.2885\n",
      "Epoch 13/100\n",
      " - 8s - loss: 2.6828 - acc: 0.2500 - val_loss: 2.6879 - val_acc: 0.2192\n",
      "Epoch 14/100\n",
      " - 8s - loss: 2.5802 - acc: 0.2777 - val_loss: 2.6027 - val_acc: 0.1846\n",
      "Epoch 15/100\n",
      " - 7s - loss: 2.4955 - acc: 0.2962 - val_loss: 2.5020 - val_acc: 0.2462\n",
      "Epoch 16/100\n",
      " - 7s - loss: 2.4009 - acc: 0.3046 - val_loss: 2.4481 - val_acc: 0.2346\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 7s - loss: 2.3158 - acc: 0.2977 - val_loss: 2.3957 - val_acc: 0.2308\n",
      "Epoch 18/100\n",
      " - 7s - loss: 2.2374 - acc: 0.3215 - val_loss: 2.3332 - val_acc: 0.2385\n",
      "Epoch 19/100\n",
      " - 7s - loss: 2.1736 - acc: 0.3092 - val_loss: 2.2876 - val_acc: 0.2423\n",
      "Epoch 20/100\n",
      " - 7s - loss: 2.0938 - acc: 0.3215 - val_loss: 2.2146 - val_acc: 0.2692\n",
      "Epoch 21/100\n",
      " - 7s - loss: 2.0396 - acc: 0.3246 - val_loss: 2.1871 - val_acc: 0.2385\n",
      "Epoch 22/100\n",
      " - 8s - loss: 1.9865 - acc: 0.3515 - val_loss: 2.1581 - val_acc: 0.2692\n",
      "Epoch 23/100\n",
      " - 8s - loss: 1.9466 - acc: 0.3700 - val_loss: 2.1001 - val_acc: 0.2808\n",
      "Epoch 24/100\n",
      " - 8s - loss: 1.8888 - acc: 0.3946 - val_loss: 2.0667 - val_acc: 0.2654\n",
      "Epoch 25/100\n",
      " - 8s - loss: 1.8449 - acc: 0.4254 - val_loss: 2.0355 - val_acc: 0.2885\n",
      "Epoch 26/100\n",
      " - 8s - loss: 1.8052 - acc: 0.4508 - val_loss: 2.0123 - val_acc: 0.3615\n",
      "Epoch 27/100\n",
      " - 7s - loss: 1.7647 - acc: 0.4415 - val_loss: 2.0043 - val_acc: 0.3308\n",
      "Epoch 28/100\n",
      " - 8s - loss: 1.7156 - acc: 0.4908 - val_loss: 1.9731 - val_acc: 0.4000\n",
      "Epoch 29/100\n",
      " - 7s - loss: 1.6723 - acc: 0.4777 - val_loss: 1.9542 - val_acc: 0.4038\n",
      "Epoch 30/100\n",
      " - 7s - loss: 1.6325 - acc: 0.5062 - val_loss: 1.9479 - val_acc: 0.3462\n",
      "Epoch 31/100\n",
      " - 8s - loss: 1.5931 - acc: 0.5185 - val_loss: 1.9762 - val_acc: 0.3231\n",
      "Epoch 32/100\n",
      " - 8s - loss: 1.5661 - acc: 0.5131 - val_loss: 1.9064 - val_acc: 0.4038\n",
      "Epoch 33/100\n",
      " - 7s - loss: 1.5197 - acc: 0.5462 - val_loss: 1.9516 - val_acc: 0.3346\n",
      "Epoch 34/100\n",
      " - 7s - loss: 1.4784 - acc: 0.5608 - val_loss: 1.9024 - val_acc: 0.4000\n",
      "Epoch 35/100\n",
      " - 7s - loss: 1.4481 - acc: 0.5738 - val_loss: 1.9221 - val_acc: 0.4154\n",
      "Epoch 36/100\n",
      " - 8s - loss: 1.4162 - acc: 0.5800 - val_loss: 1.8983 - val_acc: 0.3500\n",
      "Epoch 37/100\n",
      " - 8s - loss: 1.3756 - acc: 0.5808 - val_loss: 1.8454 - val_acc: 0.3885\n",
      "Epoch 38/100\n",
      " - 8s - loss: 1.3372 - acc: 0.5938 - val_loss: 1.8195 - val_acc: 0.4385\n",
      "Epoch 39/100\n",
      " - 7s - loss: 1.3110 - acc: 0.6269 - val_loss: 1.8476 - val_acc: 0.3654\n",
      "Epoch 40/100\n",
      " - 7s - loss: 1.2757 - acc: 0.6385 - val_loss: 1.8193 - val_acc: 0.3923\n",
      "Epoch 41/100\n",
      " - 7s - loss: 1.2352 - acc: 0.6485 - val_loss: 1.7983 - val_acc: 0.3885\n",
      "Epoch 42/100\n",
      " - 8s - loss: 1.2264 - acc: 0.6538 - val_loss: 1.8475 - val_acc: 0.4000\n",
      "Epoch 43/100\n",
      " - 8s - loss: 1.1940 - acc: 0.6708 - val_loss: 1.7751 - val_acc: 0.4500\n",
      "Epoch 44/100\n",
      " - 7s - loss: 1.1536 - acc: 0.6731 - val_loss: 1.7615 - val_acc: 0.4308\n",
      "Epoch 45/100\n",
      " - 7s - loss: 1.1319 - acc: 0.6877 - val_loss: 1.8405 - val_acc: 0.4077\n",
      "Epoch 46/100\n",
      " - 7s - loss: 1.0951 - acc: 0.6992 - val_loss: 1.7355 - val_acc: 0.5000\n",
      "Epoch 47/100\n",
      " - 8s - loss: 1.0639 - acc: 0.7077 - val_loss: 1.7452 - val_acc: 0.5231\n",
      "Epoch 48/100\n",
      " - 7s - loss: 1.0433 - acc: 0.6992 - val_loss: 1.7313 - val_acc: 0.5000\n",
      "Epoch 49/100\n",
      " - 7s - loss: 1.0102 - acc: 0.7300 - val_loss: 1.7090 - val_acc: 0.5500\n",
      "Epoch 50/100\n",
      " - 7s - loss: 0.9941 - acc: 0.7515 - val_loss: 1.7298 - val_acc: 0.5000\n",
      "Epoch 51/100\n",
      " - 7s - loss: 0.9559 - acc: 0.7454 - val_loss: 1.7112 - val_acc: 0.4962\n",
      "Epoch 52/100\n",
      " - 7s - loss: 0.9080 - acc: 0.7815 - val_loss: 1.7971 - val_acc: 0.5308\n",
      "Epoch 53/100\n",
      " - 7s - loss: 0.8993 - acc: 0.7700 - val_loss: 1.6496 - val_acc: 0.5846\n",
      "Epoch 54/100\n",
      " - 7s - loss: 0.8775 - acc: 0.7862 - val_loss: 1.6758 - val_acc: 0.5346\n",
      "Epoch 55/100\n",
      " - 7s - loss: 0.8580 - acc: 0.7746 - val_loss: 1.7853 - val_acc: 0.5038\n",
      "Epoch 56/100\n",
      " - 7s - loss: 0.8300 - acc: 0.7962 - val_loss: 1.6450 - val_acc: 0.5500\n",
      "Epoch 57/100\n",
      " - 7s - loss: 0.8195 - acc: 0.8038 - val_loss: 1.5892 - val_acc: 0.5808\n",
      "Epoch 58/100\n",
      " - 7s - loss: 0.7755 - acc: 0.8008 - val_loss: 1.6954 - val_acc: 0.4885\n",
      "Epoch 59/100\n",
      " - 7s - loss: 0.7641 - acc: 0.8115 - val_loss: 1.6619 - val_acc: 0.5808\n",
      "Epoch 60/100\n",
      " - 7s - loss: 0.7340 - acc: 0.8323 - val_loss: 1.7209 - val_acc: 0.5500\n",
      "Epoch 61/100\n",
      " - 7s - loss: 0.7157 - acc: 0.8208 - val_loss: 1.6541 - val_acc: 0.5654\n",
      "Epoch 62/100\n",
      " - 7s - loss: 0.6839 - acc: 0.8392 - val_loss: 1.5763 - val_acc: 0.5808\n",
      "Epoch 63/100\n",
      " - 7s - loss: 0.6786 - acc: 0.8362 - val_loss: 1.6194 - val_acc: 0.5885\n",
      "Epoch 64/100\n",
      " - 7s - loss: 0.6467 - acc: 0.8377 - val_loss: 1.5841 - val_acc: 0.5846\n",
      "Epoch 65/100\n",
      " - 7s - loss: 0.6264 - acc: 0.8538 - val_loss: 1.6245 - val_acc: 0.6115\n",
      "Epoch 66/100\n",
      " - 7s - loss: 0.5993 - acc: 0.8631 - val_loss: 1.5994 - val_acc: 0.5808\n",
      "Epoch 67/100\n",
      " - 7s - loss: 0.5904 - acc: 0.8623 - val_loss: 1.5772 - val_acc: 0.5885\n",
      "Epoch 00067: early stopping\n",
      "2\n",
      "Train on 1300 samples, validate on 260 samples\n",
      "Epoch 1/100\n",
      " - 8s - loss: 3.2751 - acc: 0.0385 - val_loss: 3.2606 - val_acc: 0.0385\n",
      "Epoch 2/100\n",
      " - 7s - loss: 3.2610 - acc: 0.0331 - val_loss: 3.2523 - val_acc: 0.0385\n",
      "Epoch 3/100\n",
      " - 7s - loss: 3.2462 - acc: 0.0446 - val_loss: 3.2390 - val_acc: 0.1038\n",
      "Epoch 4/100\n",
      " - 8s - loss: 3.2209 - acc: 0.1008 - val_loss: 3.2119 - val_acc: 0.0731\n",
      "Epoch 5/100\n",
      " - 7s - loss: 3.1871 - acc: 0.1146 - val_loss: 3.1808 - val_acc: 0.0731\n",
      "Epoch 6/100\n",
      " - 7s - loss: 3.1432 - acc: 0.1292 - val_loss: 3.1250 - val_acc: 0.1500\n",
      "Epoch 7/100\n",
      " - 7s - loss: 3.0811 - acc: 0.1623 - val_loss: 3.0594 - val_acc: 0.1231\n",
      "Epoch 8/100\n",
      " - 7s - loss: 3.0046 - acc: 0.1615 - val_loss: 2.9806 - val_acc: 0.1500\n",
      "Epoch 9/100\n",
      " - 7s - loss: 2.9208 - acc: 0.1669 - val_loss: 2.8902 - val_acc: 0.1500\n",
      "Epoch 10/100\n",
      " - 7s - loss: 2.8263 - acc: 0.1862 - val_loss: 2.8067 - val_acc: 0.1692\n",
      "Epoch 11/100\n",
      " - 7s - loss: 2.7410 - acc: 0.2069 - val_loss: 2.7504 - val_acc: 0.1500\n",
      "Epoch 12/100\n",
      " - 7s - loss: 2.6497 - acc: 0.2454 - val_loss: 2.6694 - val_acc: 0.2346\n",
      "Epoch 13/100\n",
      " - 7s - loss: 2.5737 - acc: 0.2362 - val_loss: 2.6022 - val_acc: 0.2385\n",
      "Epoch 14/100\n",
      " - 7s - loss: 2.4956 - acc: 0.2769 - val_loss: 2.5238 - val_acc: 0.2192\n",
      "Epoch 15/100\n",
      " - 7s - loss: 2.4218 - acc: 0.2923 - val_loss: 2.5023 - val_acc: 0.2500\n",
      "Epoch 16/100\n",
      " - 7s - loss: 2.3551 - acc: 0.3269 - val_loss: 2.4055 - val_acc: 0.2654\n",
      "Epoch 17/100\n",
      " - 7s - loss: 2.2911 - acc: 0.3123 - val_loss: 2.3747 - val_acc: 0.2077\n",
      "Epoch 18/100\n",
      " - 7s - loss: 2.2239 - acc: 0.3438 - val_loss: 2.3130 - val_acc: 0.2769\n",
      "Epoch 19/100\n",
      " - 7s - loss: 2.1626 - acc: 0.3723 - val_loss: 2.2549 - val_acc: 0.3231\n",
      "Epoch 20/100\n",
      " - 7s - loss: 2.1039 - acc: 0.3731 - val_loss: 2.2414 - val_acc: 0.2885\n",
      "Epoch 21/100\n",
      " - 7s - loss: 2.0485 - acc: 0.3962 - val_loss: 2.1745 - val_acc: 0.3115\n",
      "Epoch 22/100\n",
      " - 7s - loss: 2.0016 - acc: 0.3954 - val_loss: 2.1285 - val_acc: 0.3346\n",
      "Epoch 23/100\n",
      " - 7s - loss: 1.9504 - acc: 0.3992 - val_loss: 2.1234 - val_acc: 0.3231\n",
      "Epoch 24/100\n",
      " - 7s - loss: 1.9017 - acc: 0.4085 - val_loss: 2.0753 - val_acc: 0.3385\n",
      "Epoch 25/100\n",
      " - 7s - loss: 1.8496 - acc: 0.4223 - val_loss: 2.0461 - val_acc: 0.3538\n",
      "Epoch 26/100\n",
      " - 7s - loss: 1.7999 - acc: 0.4492 - val_loss: 2.0484 - val_acc: 0.3269\n",
      "Epoch 27/100\n",
      " - 7s - loss: 1.7620 - acc: 0.4592 - val_loss: 2.0177 - val_acc: 0.3769\n",
      "Epoch 28/100\n",
      " - 7s - loss: 1.7394 - acc: 0.4592 - val_loss: 1.9954 - val_acc: 0.3654\n",
      "Epoch 29/100\n",
      " - 7s - loss: 1.6903 - acc: 0.4877 - val_loss: 1.9683 - val_acc: 0.3423\n",
      "Epoch 30/100\n",
      " - 7s - loss: 1.6559 - acc: 0.4877 - val_loss: 1.9911 - val_acc: 0.3269\n",
      "Epoch 31/100\n",
      " - 7s - loss: 1.6110 - acc: 0.4946 - val_loss: 1.9471 - val_acc: 0.3923\n",
      "Epoch 32/100\n",
      " - 7s - loss: 1.5832 - acc: 0.5108 - val_loss: 1.9445 - val_acc: 0.3654\n",
      "Epoch 33/100\n",
      " - 7s - loss: 1.5482 - acc: 0.5077 - val_loss: 2.0244 - val_acc: 0.3538\n",
      "Epoch 34/100\n",
      " - 7s - loss: 1.5128 - acc: 0.5654 - val_loss: 1.9609 - val_acc: 0.3654\n",
      "Epoch 35/100\n",
      " - 7s - loss: 1.4716 - acc: 0.5531 - val_loss: 1.9223 - val_acc: 0.3885\n",
      "Epoch 36/100\n",
      " - 7s - loss: 1.4433 - acc: 0.5685 - val_loss: 1.8840 - val_acc: 0.4192\n",
      "Epoch 37/100\n",
      " - 7s - loss: 1.3895 - acc: 0.6123 - val_loss: 1.8679 - val_acc: 0.3962\n",
      "Epoch 38/100\n",
      " - 7s - loss: 1.3629 - acc: 0.6154 - val_loss: 1.8797 - val_acc: 0.4654\n",
      "Epoch 39/100\n",
      " - 7s - loss: 1.3235 - acc: 0.6315 - val_loss: 1.8828 - val_acc: 0.4346\n",
      "Epoch 40/100\n",
      " - 7s - loss: 1.2868 - acc: 0.6531 - val_loss: 1.8631 - val_acc: 0.4154\n",
      "Epoch 41/100\n",
      " - 7s - loss: 1.2526 - acc: 0.6615 - val_loss: 1.8673 - val_acc: 0.4923\n",
      "Epoch 42/100\n",
      " - 7s - loss: 1.2111 - acc: 0.6846 - val_loss: 1.7992 - val_acc: 0.4500\n",
      "Epoch 43/100\n",
      " - 7s - loss: 1.1821 - acc: 0.6862 - val_loss: 1.7641 - val_acc: 0.4538\n",
      "Epoch 44/100\n",
      " - 7s - loss: 1.1333 - acc: 0.7169 - val_loss: 1.8906 - val_acc: 0.3846\n",
      "Epoch 45/100\n",
      " - 7s - loss: 1.1011 - acc: 0.7200 - val_loss: 1.8320 - val_acc: 0.4577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      " - 7s - loss: 1.0771 - acc: 0.7300 - val_loss: 1.8164 - val_acc: 0.4846\n",
      "Epoch 47/100\n",
      " - 7s - loss: 1.0384 - acc: 0.7462 - val_loss: 1.7324 - val_acc: 0.4615\n",
      "Epoch 48/100\n",
      " - 7s - loss: 1.0020 - acc: 0.7585 - val_loss: 1.7693 - val_acc: 0.5154\n",
      "Epoch 49/100\n",
      " - 7s - loss: 0.9865 - acc: 0.7623 - val_loss: 1.7128 - val_acc: 0.5654\n",
      "Epoch 50/100\n",
      " - 7s - loss: 0.9335 - acc: 0.7923 - val_loss: 1.7047 - val_acc: 0.5692\n",
      "Epoch 51/100\n",
      " - 7s - loss: 0.8974 - acc: 0.8015 - val_loss: 1.6076 - val_acc: 0.5615\n",
      "Epoch 52/100\n",
      " - 7s - loss: 0.8867 - acc: 0.8062 - val_loss: 1.6351 - val_acc: 0.5808\n",
      "Epoch 53/100\n",
      " - 7s - loss: 0.8411 - acc: 0.8146 - val_loss: 1.5981 - val_acc: 0.5846\n",
      "Epoch 54/100\n",
      " - 7s - loss: 0.8286 - acc: 0.8246 - val_loss: 1.5555 - val_acc: 0.5923\n",
      "Epoch 55/100\n",
      " - 7s - loss: 0.7806 - acc: 0.8446 - val_loss: 1.6025 - val_acc: 0.5885\n",
      "Epoch 56/100\n",
      " - 7s - loss: 0.7613 - acc: 0.8462 - val_loss: 1.5948 - val_acc: 0.6462\n",
      "Epoch 57/100\n",
      " - 7s - loss: 0.7411 - acc: 0.8485 - val_loss: 1.5764 - val_acc: 0.6000\n",
      "Epoch 58/100\n",
      " - 7s - loss: 0.7052 - acc: 0.8754 - val_loss: 1.5856 - val_acc: 0.6077\n",
      "Epoch 59/100\n",
      " - 7s - loss: 0.6982 - acc: 0.8662 - val_loss: 1.5832 - val_acc: 0.6269\n",
      "Epoch 00059: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n",
      "Final accuracy: 0.6730769230769231\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import LSTM\n",
    "checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "for i in range(3):\n",
    "    print(i)\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, activation='sigmoid', dropout=0.1, recurrent_dropout=0.1, input_shape=(200,200)))\n",
    "    model.add(Dense(30, activation='sigmoid'))\n",
    "    model.add(Dense(y_train.shape[1], activation='sigmoid'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2,epochs=100)\n",
    "\n",
    "print('Training finished...Loading the best model')  \n",
    "print()\n",
    "model.load_weights('best_weights.hdf5') # load weights from best model\n",
    "\n",
    "# Measure accuracy\n",
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "score = metrics.accuracy_score(y_true, pred)\n",
    "print(\"Final accuracy: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.00      0.00      0.00        10\n",
      "          1       0.56      0.50      0.53        10\n",
      "          2       0.28      0.80      0.41        10\n",
      "          3       0.62      0.50      0.56        10\n",
      "          4       0.73      0.80      0.76        10\n",
      "          5       0.50      0.10      0.17        10\n",
      "          6       1.00      1.00      1.00        10\n",
      "          7       1.00      1.00      1.00        10\n",
      "          8       1.00      0.50      0.67        10\n",
      "          9       1.00      1.00      1.00        10\n",
      "         10       1.00      1.00      1.00        10\n",
      "         11       0.83      1.00      0.91        10\n",
      "         12       1.00      0.10      0.18        10\n",
      "         13       0.47      0.80      0.59        10\n",
      "         14       1.00      1.00      1.00        10\n",
      "         15       0.91      1.00      0.95        10\n",
      "         16       1.00      0.10      0.18        10\n",
      "         17       0.67      0.80      0.73        10\n",
      "         18       0.83      1.00      0.91        10\n",
      "         19       0.73      0.80      0.76        10\n",
      "         20       0.36      0.40      0.38        10\n",
      "         21       0.45      0.90      0.60        10\n",
      "         22       0.40      0.20      0.27        10\n",
      "         23       1.00      0.70      0.82        10\n",
      "         24       0.47      0.70      0.56        10\n",
      "         25       0.73      0.80      0.76        10\n",
      "\n",
      "avg / total       0.71      0.67      0.64       260\n",
      "\n",
      "Precision : 0.6730769230769231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, pred)\n",
    "print('Plotting confusion matrix')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, alphabet_array)\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_true, pred))\n",
    "print(\"Precision :\", metrics.accuracy_score(y_true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1300, 200, 200)\n",
      "(260, 200, 200)\n",
      "(1300, 26)\n",
      "(260, 26)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Conv1D -> LSTM -> Neural Network</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Train on 1300 samples, validate on 260 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 3.3162 - val_loss: 3.2186\n",
      "Epoch 2/100\n",
      " - 6s - loss: 3.1141 - val_loss: 2.9372\n",
      "Epoch 3/100\n",
      " - 6s - loss: 2.8482 - val_loss: 2.7372\n",
      "Epoch 4/100\n",
      " - 6s - loss: 2.6362 - val_loss: 2.5293\n",
      "Epoch 5/100\n",
      " - 6s - loss: 2.4285 - val_loss: 2.4011\n",
      "Epoch 6/100\n",
      " - 6s - loss: 2.2405 - val_loss: 2.2613\n",
      "Epoch 7/100\n",
      " - 6s - loss: 2.1024 - val_loss: 2.1887\n",
      "Epoch 8/100\n",
      " - 6s - loss: 1.9735 - val_loss: 2.0811\n",
      "Epoch 9/100\n",
      " - 6s - loss: 1.8709 - val_loss: 2.0161\n",
      "Epoch 10/100\n",
      " - 6s - loss: 1.7847 - val_loss: 1.9357\n",
      "Epoch 11/100\n",
      " - 6s - loss: 1.6852 - val_loss: 1.9283\n",
      "Epoch 12/100\n",
      " - 6s - loss: 1.5794 - val_loss: 1.8571\n",
      "Epoch 13/100\n",
      " - 6s - loss: 1.5025 - val_loss: 1.8661\n",
      "Epoch 14/100\n",
      " - 6s - loss: 1.4617 - val_loss: 1.7800\n",
      "Epoch 15/100\n",
      " - 6s - loss: 1.3931 - val_loss: 1.7841\n",
      "Epoch 16/100\n",
      " - 6s - loss: 1.3253 - val_loss: 1.8663\n",
      "Epoch 17/100\n",
      " - 6s - loss: 1.2816 - val_loss: 1.7579\n",
      "Epoch 18/100\n",
      " - 6s - loss: 1.2300 - val_loss: 1.6937\n",
      "Epoch 19/100\n",
      " - 6s - loss: 1.1738 - val_loss: 1.6689\n",
      "Epoch 20/100\n",
      " - 6s - loss: 1.1315 - val_loss: 1.6555\n",
      "Epoch 21/100\n",
      " - 6s - loss: 1.0828 - val_loss: 1.7158\n",
      "Epoch 22/100\n",
      " - 6s - loss: 1.0222 - val_loss: 1.6328\n",
      "Epoch 23/100\n",
      " - 6s - loss: 0.9723 - val_loss: 1.5633\n",
      "Epoch 24/100\n",
      " - 7s - loss: 0.9008 - val_loss: 1.5605\n",
      "Epoch 25/100\n",
      " - 6s - loss: 0.8487 - val_loss: 1.4738\n",
      "Epoch 26/100\n",
      " - 6s - loss: 0.7860 - val_loss: 1.6624\n",
      "Epoch 27/100\n",
      " - 6s - loss: 0.7490 - val_loss: 1.5808\n",
      "Epoch 28/100\n",
      " - 6s - loss: 0.6932 - val_loss: 1.4694\n",
      "Epoch 29/100\n",
      " - 6s - loss: 0.6485 - val_loss: 1.3763\n",
      "Epoch 30/100\n",
      " - 6s - loss: 0.5870 - val_loss: 1.4776\n",
      "Epoch 31/100\n",
      " - 6s - loss: 0.5739 - val_loss: 1.3268\n",
      "Epoch 32/100\n",
      " - 6s - loss: 0.5028 - val_loss: 1.4533\n",
      "Epoch 33/100\n",
      " - 6s - loss: 0.4604 - val_loss: 1.4198\n",
      "Epoch 34/100\n",
      " - 6s - loss: 0.4617 - val_loss: 1.3548\n",
      "Epoch 35/100\n",
      " - 6s - loss: 0.3978 - val_loss: 1.9315\n",
      "Epoch 36/100\n",
      " - 7s - loss: 0.3830 - val_loss: 1.4279\n",
      "Epoch 00036: early stopping\n",
      "1\n",
      "Train on 1300 samples, validate on 260 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 3.2878 - val_loss: 3.2090\n",
      "Epoch 2/100\n",
      " - 6s - loss: 3.0860 - val_loss: 2.9178\n",
      "Epoch 3/100\n",
      " - 6s - loss: 2.8139 - val_loss: 2.7125\n",
      "Epoch 4/100\n",
      " - 6s - loss: 2.6104 - val_loss: 2.5723\n",
      "Epoch 5/100\n",
      " - 6s - loss: 2.4290 - val_loss: 2.4137\n",
      "Epoch 6/100\n",
      " - 6s - loss: 2.2831 - val_loss: 2.3373\n",
      "Epoch 7/100\n",
      " - 6s - loss: 2.1578 - val_loss: 2.2066\n",
      "Epoch 8/100\n",
      " - 6s - loss: 2.0543 - val_loss: 2.2057\n",
      "Epoch 9/100\n",
      " - 6s - loss: 1.9414 - val_loss: 2.1454\n",
      "Epoch 10/100\n",
      " - 6s - loss: 1.8599 - val_loss: 2.2163\n",
      "Epoch 11/100\n",
      " - 6s - loss: 1.7899 - val_loss: 1.9940\n",
      "Epoch 12/100\n",
      " - 6s - loss: 1.7136 - val_loss: 2.0943\n",
      "Epoch 13/100\n",
      " - 6s - loss: 1.6279 - val_loss: 1.9140\n",
      "Epoch 14/100\n",
      " - 6s - loss: 1.5486 - val_loss: 1.8445\n",
      "Epoch 15/100\n",
      " - 6s - loss: 1.4894 - val_loss: 1.8662\n",
      "Epoch 16/100\n",
      " - 6s - loss: 1.4239 - val_loss: 1.8133\n",
      "Epoch 17/100\n",
      " - 6s - loss: 1.3687 - val_loss: 1.9454\n",
      "Epoch 18/100\n",
      " - 6s - loss: 1.3178 - val_loss: 1.7099\n",
      "Epoch 19/100\n",
      " - 6s - loss: 1.2466 - val_loss: 1.7635\n",
      "Epoch 20/100\n",
      " - 6s - loss: 1.2149 - val_loss: 1.6971\n",
      "Epoch 21/100\n",
      " - 6s - loss: 1.1590 - val_loss: 1.8118\n",
      "Epoch 22/100\n",
      " - 6s - loss: 1.1133 - val_loss: 1.6391\n",
      "Epoch 23/100\n",
      " - 6s - loss: 1.0416 - val_loss: 1.6527\n",
      "Epoch 24/100\n",
      " - 6s - loss: 1.0044 - val_loss: 1.6250\n",
      "Epoch 25/100\n",
      " - 6s - loss: 0.9312 - val_loss: 1.5390\n",
      "Epoch 26/100\n",
      " - 6s - loss: 0.8905 - val_loss: 1.5498\n",
      "Epoch 27/100\n",
      " - 6s - loss: 0.8495 - val_loss: 1.5429\n",
      "Epoch 28/100\n",
      " - 6s - loss: 0.7835 - val_loss: 1.3933\n",
      "Epoch 29/100\n",
      " - 6s - loss: 0.7381 - val_loss: 1.5029\n",
      "Epoch 30/100\n",
      " - 6s - loss: 0.6836 - val_loss: 1.5756\n",
      "Epoch 31/100\n",
      " - 6s - loss: 0.6149 - val_loss: 1.3623\n",
      "Epoch 32/100\n",
      " - 6s - loss: 0.5733 - val_loss: 1.3256\n",
      "Epoch 33/100\n",
      " - 6s - loss: 0.5270 - val_loss: 1.3022\n",
      "Epoch 34/100\n",
      " - 7s - loss: 0.4772 - val_loss: 1.2751\n",
      "Epoch 35/100\n",
      " - 6s - loss: 0.4451 - val_loss: 1.1697\n",
      "Epoch 36/100\n",
      " - 6s - loss: 0.4188 - val_loss: 1.1685\n",
      "Epoch 37/100\n",
      " - 6s - loss: 0.3438 - val_loss: 1.0386\n",
      "Epoch 38/100\n",
      " - 6s - loss: 0.3397 - val_loss: 1.1209\n",
      "Epoch 39/100\n",
      " - 6s - loss: 0.3071 - val_loss: 1.3624\n",
      "Epoch 40/100\n",
      " - 6s - loss: 0.2603 - val_loss: 1.3709\n",
      "Epoch 41/100\n",
      " - 6s - loss: 0.2417 - val_loss: 1.2638\n",
      "Epoch 42/100\n",
      " - 6s - loss: 0.2058 - val_loss: 0.9379\n",
      "Epoch 43/100\n",
      " - 7s - loss: 0.2003 - val_loss: 1.1924\n",
      "Epoch 44/100\n",
      " - 6s - loss: 0.1827 - val_loss: 1.0775\n",
      "Epoch 45/100\n",
      " - 6s - loss: 0.1581 - val_loss: 1.3406\n",
      "Epoch 46/100\n",
      " - 6s - loss: 0.1300 - val_loss: 1.0796\n",
      "Epoch 47/100\n",
      " - 6s - loss: 0.1446 - val_loss: 0.9448\n",
      "Epoch 00047: early stopping\n",
      "2\n",
      "Train on 1300 samples, validate on 260 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 3.3134 - val_loss: 3.2072\n",
      "Epoch 2/100\n",
      " - 6s - loss: 3.1104 - val_loss: 2.9296\n",
      "Epoch 3/100\n",
      " - 6s - loss: 2.8265 - val_loss: 2.7510\n",
      "Epoch 4/100\n",
      " - 6s - loss: 2.6184 - val_loss: 2.5628\n",
      "Epoch 5/100\n",
      " - 6s - loss: 2.4191 - val_loss: 2.4220\n",
      "Epoch 6/100\n",
      " - 6s - loss: 2.2250 - val_loss: 2.2529\n",
      "Epoch 7/100\n",
      " - 6s - loss: 2.0715 - val_loss: 2.1915\n",
      "Epoch 8/100\n",
      " - 6s - loss: 1.9254 - val_loss: 2.1160\n",
      "Epoch 9/100\n",
      " - 6s - loss: 1.8211 - val_loss: 2.0357\n",
      "Epoch 10/100\n",
      " - 6s - loss: 1.7146 - val_loss: 1.9879\n",
      "Epoch 11/100\n",
      " - 6s - loss: 1.6388 - val_loss: 1.9180\n",
      "Epoch 12/100\n",
      " - 6s - loss: 1.5603 - val_loss: 1.9103\n",
      "Epoch 13/100\n",
      " - 6s - loss: 1.4850 - val_loss: 1.8679\n",
      "Epoch 14/100\n",
      " - 6s - loss: 1.3915 - val_loss: 1.8343\n",
      "Epoch 15/100\n",
      " - 6s - loss: 1.3291 - val_loss: 1.8327\n",
      "Epoch 16/100\n",
      " - 6s - loss: 1.2731 - val_loss: 1.8204\n",
      "Epoch 17/100\n",
      " - 6s - loss: 1.2065 - val_loss: 1.7322\n",
      "Epoch 18/100\n",
      " - 6s - loss: 1.1507 - val_loss: 1.7891\n",
      "Epoch 19/100\n",
      " - 6s - loss: 1.1072 - val_loss: 1.6716\n",
      "Epoch 20/100\n",
      " - 6s - loss: 1.0632 - val_loss: 1.7511\n",
      "Epoch 21/100\n",
      " - 6s - loss: 1.0342 - val_loss: 1.6487\n",
      "Epoch 22/100\n",
      " - 6s - loss: 1.0033 - val_loss: 1.6902\n",
      "Epoch 23/100\n",
      " - 6s - loss: 0.9674 - val_loss: 1.7301\n",
      "Epoch 24/100\n",
      " - 6s - loss: 0.9141 - val_loss: 1.6367\n",
      "Epoch 25/100\n",
      " - 6s - loss: 0.8790 - val_loss: 1.6443\n",
      "Epoch 26/100\n",
      " - 6s - loss: 0.8728 - val_loss: 1.6374\n",
      "Epoch 27/100\n",
      " - 6s - loss: 0.8225 - val_loss: 1.7956\n",
      "Epoch 28/100\n",
      " - 6s - loss: 0.7863 - val_loss: 1.6174\n",
      "Epoch 29/100\n",
      " - 6s - loss: 0.7685 - val_loss: 1.6978\n",
      "Epoch 30/100\n",
      " - 6s - loss: 0.7377 - val_loss: 1.6442\n",
      "Epoch 31/100\n",
      " - 6s - loss: 0.7037 - val_loss: 1.6316\n",
      "Epoch 32/100\n",
      " - 6s - loss: 0.6592 - val_loss: 2.0529\n",
      "Epoch 33/100\n",
      " - 6s - loss: 0.6503 - val_loss: 1.7508\n",
      "Epoch 00033: early stopping\n",
      "3\n",
      "Train on 1300 samples, validate on 260 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 3.2925 - val_loss: 3.2168\n",
      "Epoch 2/100\n",
      " - 6s - loss: 3.0730 - val_loss: 2.9023\n",
      "Epoch 3/100\n",
      " - 6s - loss: 2.7974 - val_loss: 2.7173\n",
      "Epoch 4/100\n",
      " - 6s - loss: 2.6055 - val_loss: 2.5673\n",
      "Epoch 5/100\n",
      " - 6s - loss: 2.4512 - val_loss: 2.4584\n",
      "Epoch 6/100\n",
      " - 6s - loss: 2.3022 - val_loss: 2.3764\n",
      "Epoch 7/100\n",
      " - 6s - loss: 2.1717 - val_loss: 2.2936\n",
      "Epoch 8/100\n",
      " - 6s - loss: 2.0334 - val_loss: 2.2225\n",
      "Epoch 9/100\n",
      " - 6s - loss: 1.9042 - val_loss: 2.1432\n",
      "Epoch 10/100\n",
      " - 6s - loss: 1.7969 - val_loss: 2.1396\n",
      "Epoch 11/100\n",
      " - 6s - loss: 1.7086 - val_loss: 2.2059\n",
      "Epoch 12/100\n",
      " - 6s - loss: 1.6032 - val_loss: 1.9941\n",
      "Epoch 13/100\n",
      " - 6s - loss: 1.5189 - val_loss: 2.0607\n",
      "Epoch 14/100\n",
      " - 6s - loss: 1.4443 - val_loss: 1.9553\n",
      "Epoch 15/100\n",
      " - 6s - loss: 1.3719 - val_loss: 1.8957\n",
      "Epoch 16/100\n",
      " - 6s - loss: 1.3103 - val_loss: 1.9807\n",
      "Epoch 17/100\n",
      " - 6s - loss: 1.2571 - val_loss: 1.8583\n",
      "Epoch 18/100\n",
      " - 6s - loss: 1.2032 - val_loss: 1.8911\n",
      "Epoch 19/100\n",
      " - 6s - loss: 1.1558 - val_loss: 1.7661\n",
      "Epoch 20/100\n",
      " - 6s - loss: 1.1379 - val_loss: 1.7597\n",
      "Epoch 21/100\n",
      " - 6s - loss: 1.0811 - val_loss: 1.7522\n",
      "Epoch 22/100\n",
      " - 6s - loss: 1.0615 - val_loss: 1.8575\n",
      "Epoch 23/100\n",
      " - 6s - loss: 1.0284 - val_loss: 1.8365\n",
      "Epoch 24/100\n",
      " - 6s - loss: 0.9987 - val_loss: 1.7798\n",
      "Epoch 25/100\n",
      " - 6s - loss: 0.9609 - val_loss: 1.7227\n",
      "Epoch 26/100\n",
      " - 6s - loss: 0.9300 - val_loss: 1.6982\n",
      "Epoch 27/100\n",
      " - 6s - loss: 0.8928 - val_loss: 1.7188\n",
      "Epoch 28/100\n",
      " - 6s - loss: 0.8875 - val_loss: 1.7661\n",
      "Epoch 29/100\n",
      " - 6s - loss: 0.8488 - val_loss: 1.7018\n",
      "Epoch 30/100\n",
      " - 6s - loss: 0.8337 - val_loss: 1.6855\n",
      "Epoch 31/100\n",
      " - 6s - loss: 0.7800 - val_loss: 1.7597\n",
      "Epoch 32/100\n",
      " - 6s - loss: 0.7860 - val_loss: 1.9367\n",
      "Epoch 33/100\n",
      " - 6s - loss: 0.7454 - val_loss: 1.7338\n",
      "Epoch 34/100\n",
      " - 6s - loss: 0.7301 - val_loss: 1.7023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      " - 6s - loss: 0.7080 - val_loss: 1.9744\n",
      "Epoch 00035: early stopping\n",
      "4\n",
      "Train on 1300 samples, validate on 260 samples\n",
      "Epoch 1/100\n",
      " - 9s - loss: 3.3235 - val_loss: 3.2347\n",
      "Epoch 2/100\n",
      " - 6s - loss: 3.1488 - val_loss: 2.9870\n",
      "Epoch 3/100\n",
      " - 6s - loss: 2.8840 - val_loss: 2.8068\n",
      "Epoch 4/100\n",
      " - 6s - loss: 2.6962 - val_loss: 2.6622\n",
      "Epoch 5/100\n",
      " - 6s - loss: 2.5253 - val_loss: 2.5188\n",
      "Epoch 6/100\n",
      " - 6s - loss: 2.3371 - val_loss: 2.3818\n",
      "Epoch 7/100\n",
      " - 6s - loss: 2.1323 - val_loss: 2.2422\n",
      "Epoch 8/100\n",
      " - 6s - loss: 1.9747 - val_loss: 2.1117\n",
      "Epoch 9/100\n",
      " - 6s - loss: 1.8327 - val_loss: 2.0169\n",
      "Epoch 10/100\n",
      " - 6s - loss: 1.7106 - val_loss: 1.9220\n",
      "Epoch 11/100\n",
      " - 6s - loss: 1.5945 - val_loss: 1.8585\n",
      "Epoch 12/100\n",
      " - 6s - loss: 1.5051 - val_loss: 1.8387\n",
      "Epoch 13/100\n",
      " - 6s - loss: 1.4185 - val_loss: 1.8258\n",
      "Epoch 14/100\n",
      " - 6s - loss: 1.3561 - val_loss: 1.7459\n",
      "Epoch 15/100\n",
      " - 6s - loss: 1.2860 - val_loss: 1.7461\n",
      "Epoch 16/100\n",
      " - 6s - loss: 1.2234 - val_loss: 1.7633\n",
      "Epoch 17/100\n",
      " - 6s - loss: 1.1787 - val_loss: 1.6534\n",
      "Epoch 18/100\n",
      " - 6s - loss: 1.1369 - val_loss: 1.6660\n",
      "Epoch 19/100\n",
      " - 6s - loss: 1.0794 - val_loss: 1.7808\n",
      "Epoch 20/100\n",
      " - 6s - loss: 1.0526 - val_loss: 1.6019\n",
      "Epoch 21/100\n",
      " - 6s - loss: 1.0269 - val_loss: 1.6063\n",
      "Epoch 22/100\n",
      " - 6s - loss: 0.9686 - val_loss: 1.5879\n",
      "Epoch 23/100\n",
      " - 6s - loss: 0.9373 - val_loss: 1.6396\n",
      "Epoch 24/100\n",
      " - 6s - loss: 0.8931 - val_loss: 1.6114\n",
      "Epoch 25/100\n",
      " - 6s - loss: 0.8560 - val_loss: 1.5559\n",
      "Epoch 26/100\n",
      " - 6s - loss: 0.8236 - val_loss: 1.7034\n",
      "Epoch 27/100\n",
      " - 6s - loss: 0.7965 - val_loss: 1.5153\n",
      "Epoch 28/100\n",
      " - 6s - loss: 0.7328 - val_loss: 1.4970\n",
      "Epoch 29/100\n",
      " - 6s - loss: 0.7170 - val_loss: 1.5108\n",
      "Epoch 30/100\n",
      " - 6s - loss: 0.6742 - val_loss: 1.4403\n",
      "Epoch 31/100\n",
      " - 6s - loss: 0.6484 - val_loss: 1.7013\n",
      "Epoch 32/100\n",
      " - 6s - loss: 0.6200 - val_loss: 1.6564\n",
      "Epoch 33/100\n",
      " - 6s - loss: 0.5829 - val_loss: 1.4959\n",
      "Epoch 34/100\n",
      " - 6s - loss: 0.5574 - val_loss: 1.6208\n",
      "Epoch 35/100\n",
      " - 6s - loss: 0.5359 - val_loss: 1.4950\n",
      "Epoch 00035: early stopping\n",
      "Training finished...Loading the best model\n",
      "\n",
      "Final accuracy: 0.7307692307692307\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath=\"best_weights.hdf5\", verbose=0, save_best_only=True) # save best model\n",
    "\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "for i in range(5):\n",
    "    print(i)\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(200, kernel_size=9, padding='valid', activation='sigmoid', input_shape=(200,200)))\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(LSTM(128, activation='sigmoid'))\n",
    "    model.add(Dense(107, activation='sigmoid'))    \n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "\n",
    "    model.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer],verbose=2,epochs=100)\n",
    "\n",
    "print('Training finished...Loading the best model')  \n",
    "print()\n",
    "model.load_weights('best_weights.hdf5') # load weights from best model\n",
    "\n",
    "# Measure accuracy\n",
    "pred = model.predict(x_test)\n",
    "pred = np.argmax(pred,axis=1)\n",
    "\n",
    "y_true = np.argmax(y_test,axis=1)\n",
    "\n",
    "score = metrics.accuracy_score(y_true, pred)\n",
    "print(\"Final accuracy: {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAEmCAYAAAAeIzmqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnXe8HVW1x7+/mx5CSaEnIYAUMY+ShBZUOtKLgHTBB+SBAtJUEJSgoDylKEUwVAGFSJM8RQFBlA4BEQi9VyUBgYABQljvj70PmZx7ypxzz50z98765jOf3JnZs9c6c+asWXvvtdeWmeE4juPMp6PdCjiO4+QNN4yO4zhluGF0HMcpww2j4zhOGW4YHcdxynDD6DiOU4YbxgIiaZCk/5P0jqSrulDPXpJuaqVu7ULSFyQ92W49nHwgj2PML5L2BI4EVgVmAw8BJ5vZHV2sdx/gUGCimX3cZUVzjiQDVjKzZ9qti9MzcI8xp0g6EvgZ8CNgSWA08AtghxZUvxzwVBGMYhok9W23Dk7OMDPfcrYBiwLvAbvWKDOAYDhfi9vPgAHx3EbAK8BRwBvA68DX4rkTgY+AuVHG/sBk4PJE3WMAA/rG/f2A5whe6/PAXonjdySumwjcD7wT/5+YOHcb8EPgzljPTcCIKp+tpP+3E/rvCGwNPAW8BXw3UX4d4G7g7Vj2bKB/PPe3+Fnej593t0T93wH+CVxWOhavWTHKGBf3lwFmARu1+9nwLZvNPcZ8sj4wELiuRpnjgPWANYE1CMbh+MT5pQgGdlmC8TtH0lAzO4HghU41syFmdmEtRSQtBJwJbGVmCxOM30MVyg0D/hDLDgdOB/4gaXii2J7A14AlgP7A0TVEL0W4B8sC3wfOB/YGxgNfAL4vaYVYdh5wBDCCcO82Bb4OYGZfjGXWiJ93aqL+YQTveVJSsJk9SzCav5Y0GLgYuMTMbquhr9OLcMOYT4YDs6x2U3cv4Adm9oaZzSR4gvskzs+N5+ea2Q0Eb2mVJvX5BBgraZCZvW5mMyqU2QZ42swuM7OPzewK4Algu0SZi83sKTObA/yWYNSrMZfQnzoXuJJg9H5uZrOj/BnA6gBm9oCZ3RPlvgD8EtgwxWc6wcw+jPosgJmdDzwN3AssTXgROQXBDWM+eRMYUafvaxngxcT+i/HYp3WUGdb/AEMaVcTM3ic0Pw8CXpf0B0mrptCnpNOyif1/NqDPm2Y2L/5dMlz/SpyfU7pe0sqSfi/pn5LeJXjEI2rUDTDTzD6oU+Z8YCxwlpl9WKes04tww5hP7gY+IPSrVeM1QjOwxOh4rBneBwYn9pdKnjSzG81sc4Ln9ATBYNTTp6TTq03q1AjnEvRaycwWAb4LqM41NcMxJA0h9NteCEyOXQVOQXDDmEPM7B1Cv9o5knaUNFhSP0lbSfpJLHYFcLykxSWNiOUvb1LkQ8AXJY2WtChwbOmEpCUlbR/7Gj8kNMnnVajjBmBlSXtK6itpN2A14PdN6tQICwPvAu9Fb/bgsvP/AlbodFVtfg48YGYHEPpOz+uylk6PwQ1jTjGz0wkxjMcDM4GXgUOA38UiJwHTgYeBR4AH47FmZN0MTI11PcCCxqyDMLr9GmGkdkPiwEZZHW8C28aybxJGlLc1s1nN6NQgRxMGdmYTvNmpZecnA7+S9Lakr9SrTNIOwJaE7gMI38M4SXu1TGMn13iAt+M4ThnuMTqO45ThhtFxnF6DpIskvSHp0cSxYZJulvR0/H9ovXrcMDqO05u4hNA/nOQY4BYzWwm4Je7XxPsYHcfpVUgaA/zezMbG/ScJ0zlfl7Q0cJuZ1ZzskNvJ88OGj7CRo8vD4hbk7Tkf1a1n8YUGdFmXl9+pFwcMoxYd2GU5jpNnXnzxBWbNmlUvPrQh+iyynNnHnSYeVcTmzJxBiO8tMcXMpqS4dEkzex0gGscl6l2QW8M4cvRy3HDrXTXL/O6x+vHMB6y7fJd1OWraY3XLnLb9al2W4zh5ZoN1J7S8Tvt4DgNWqRtBBcAHD53zgZm1XokKZNbHKGknSVZlOpnjOIVEoI50W/P8Kzahif+/Ue+CLAdf9gDuAHbPUKbjOHlGgJRua55pwL7x732B6+tdkIlhjPNONyCkv3LD6DjOfDr6pNtSIOkKQq6BVSS9Iml/4BRgc0lPA5vH/Zpk1ce4I/AnM3tK0luSxpnZg+WFJE0i5sZbduSojFRzHKd9qKvN5AUwsz2qnNq0kXqyakrvQcipR/y/ovJmNsXMJpjZhGEjFs9INcdx2kr3N6Ubpts9xpjBeRNColMD+gAm6dvmQZSOU2xESz3GVpGFRrsAl5rZcmY2xsxGEdYN+XwGsh3HyTUpvcXe5jESms3lnZ3XENJE3V7ton4dYsTCtYOzT7rkgbrCd1xtmbpl6sk5duMV69bhOE6T5NBj7HbDaGYbSZon6RGC4zwPOMTMzuxu2Y7j9AAy9gbTkNWo9BwzWxNA0peAH1N/sSLHcXo9rR2VbhXtmBK4CPDvNsh1HCdvlAK8c0ZWhnGQpIcI6wQvTRildhyn8Ag68peyoR1N6fWBSyWNLQ/XSQZ4jxo9OiPVHMdpKx358xgzb9yb2d2ENX87RXAnA7wX9wBvx+n9lOIYuzeJRMNk7sPG7Dp9CCvJOY5TdLyPEQjviH3NrNLaxI7jFIoCj0qbWbrUGA3ywrm71C1zwb3Pd1lOmmS3T7w2u26ZVZdZuMu6OE6vI4ceY5aJapeSdKWkZyU9JukGSStnJd9xnJxS1D5GSQKuA35lZrvHY2sCSwJPZaGD4zg5pA3zoNOQVR/jxsBcMzuvdMDMHqpR3nGcolDUPkZgLFA344PHMTpO0VDq7NxZkitT7XGMjlNAcph2LCvDOAMYn5Esx3F6CjkN8M5K2q3AAEkHlg5IWluSZ9hxnEKTyfKpDZOJtDgneifCSl3PSpoBTAZey0K+4zg5JodN6cymBJrZa8BXspJX4vOjRtQtc9wNj9c8nybA23GcJiniqLSkecAjQD/gY+BXwM/M7JPulu04Tg+goHGMyZRjSwC/ARYFTshAtuM4eUb5nCudqUZm9gYhTvGQOBvGcZyCo46OVFuWtCMf43NR7hLl5yRNkjRd0vSZs2ZmrZrjOBkTVjZQqi1L2uXDVvyUHuDtOAVDDWwZ0o5EtSsQllB9I2vZjuPkjey9wTRkahglLQ6cB5xdvt6L4zjFpKiGsZS9uxSucxlwer2L5sz9pG7y1zSJX9OUueaAdWqeH3Pw1XXrSJM013GczhTSMHZX9m7HcXoHhTSMJRKB3iWuNLNTspLvOE4OacPAShqy7GP8NNDbcRwHQD744jiO05mOjIO305ClRoMkPZTYdisvkAzwfvutWRmq5jhOu8hjgHeumtJmNgWYArDa6uM8nMdxejvex+g4jtOZPPYx5q9x7zhOYSgNvrSqKS3pCEkzJD0q6QpJA5vRK0uPsRToXeJPZnZM1cL9OlIFZ9dj1uwP65Z55LV3ap5PE7y98wX31S1TL5DccYpIqzxGScsChwGrmdkcSb8FdgcuabSuLDN4e6C34zidaW1Lui/BCZsLDKbJ5VPaGeC9o5m9kJV8x3FyiBryGEdImp7YnxIHbAEws1clnQq8BMwBbjKzm5pRK1ej0o7jFI8G4hhnmdmEaiclDQV2AJYH3gaukrS3mV3esE6NXuA4jtMqWjz4shnwvJnNNLO5wLXAxGb0aleA93WVCngGb8cpIK1LVPsSsJ6kwXHplE2B2kuAViFXTelkgPf48RM8wNtxejuN9THWxMzulXQ18CAhxeHfifakUTzA23GcttLKAG8zO4EWrEDqhtFxnLaSx5kvvd4wjlh4QN0yG6/SacHChkkTvD107UPqlvn3/Wd3WRfH6VHkzy5mGuA9JCtZjuP0HPLoMWYyKi1pSUm/kfScpAck3S1ppyxkO46TX9KG6vS6tGNx2Px3wK/MbM94bDlg++6W7ThO/sljotosmtKbAB+Z2XmlA2b2InBWBrIdx8k7+WtJZ2IYP0eIK6qLpEnAJIBRo0d3p06O4+SEwvYxJpF0jqR/SLq//JyZTTGzCWY2YfERi2etmuM4WaN8Lm2QhWGcAYwr7ZjZNwhTddzyOU7BESCl27IkC8N4KzBQ0sGJY4MzkOs4Tu4p6Ki0mZmkHYEzJH0bmAm8D3ynu2XnjTTB2x4E7hSNHHYxZhbg/XQywFvSfsAXgKkZyXccJ6fkcfCl108JdBwnx7Sh/zANbhgdx2kbAvr0yZ9lzMowlq8QOAyYlpFsx3FyTJGb0gskqY19jJ3WbvAAb8cpGDltSudqkqIHeDtOsQhxjAUM13Ecx6lO9kYvDW4YHcdpKzm0i9kYxvIktWZ2CXBJFrJ7GqmCwLc/s3490w7rsi6zZn9Yt0yaDOmOUwv3GCOS3vOM3o7j5HXwxZvSjuO0DQEdHfmzjG4YHcdpK3lsSucqXEfSJEnTJU2fOWtmu9VxHCcDipp2LDUex+g4BSOniWq9Ke04TtsoJarNG24YHcdpIx7g7TiO04kc2sX2GEaPYewaaYK3xxx8dc3zL5y7S906emLwdpqg9Hr0xM/dk3GPMYEHeTuO4wHejuM4ZYQA71wFxwBuGB3HaTPuMdbBE9U6TvHIYx9jrnxYD/B2nIKRctZL1rYzVx6j4zjFQh7H6DiO05kc2sW25WPsC3Q94MypSr04xaFrH1K3jjRJc/OGxyD2PDpyaBnb1cf4OeDZNsl2HCdHtLKPUdJikq6W9ISkxyWt34xOmXmMpYBuSQcB3wX6SBptZi9lpYPjOPlCgj6tTVT7c+BPZraLpP7A4GYqaUdT+mlgLrCxG0XHcVo1+CJpEeCLwH4AZvYR8FEzdVU1jFFIVczs3UaFSfoCcD6wtZl5U9pxnEYGX0ZImp7Yn2JmUxL7KwAzgYslrQE8AHzTzN5vVKdaHuMMwAizdkqU9g1oNAJ7AHA9sJGZPVGpgAd4O06xECFkJyWzzGxCjfN9gXHAoWZ2r6SfA8cA32tUr6qDL2Y2ysxGx/9Hle03Y7XmAncB+9eQ6QHejlMwOpRuS8ErwCtmdm/cv5pgKBvXKU0hSbtL+m78e6Sk8U3I+gT4CrB2qS7HcQpOymUN0vRDmtk/gZclrRIPbQo81oxadQdfJJ0N9CN0av4I+A9wHrB2o8LM7D+StgVul/QvM7uw0Tocx+ldtDiM8VDg13FE+jnga81UkmZUeqKZjZP0dwAzeysKbYp4/ZbA3yTNMrPrm63LaZ40wdu9NQjcyQ+itQHeZvYQUKsfMhVpDONcSR2EARckDSc0ixsimZTWzF4Glm+0Dsdxeh85nPiSqo/xHOAaYHFJJwJ3AP/bjDBJ7zVzneM4vRMJOjqUasuSuh6jmV0q6QFgs3hoVzN7tHvVchynKORxrnTamS99COE2Rs5yODqO07PJn1lMYeQkHQdcASwDjAR+I+nY7lBG0iRJ0yVNnzlrZneIcBwnZ7QqXKeVpPEY9wbGm9l/ACSdTJhq8+NWKxOn90wBGD9+grW6fsdx8kUYlW63Fp1JYxhfLCvXlxAf5DiO0zXa4A2moVYSiTMIfYr/AWZIujHub0EYmXYcx+kyObSLNT3G0sjzDOAPieP3dEHeYEmvJPZPN7PTu1Cf042kCd5e5wd/rlvmvu9vVrfMX558o26ZjVdZom4Zp+fRozzGVkzXk2TA5Wa2TzzUH3gduNfMtu1q/Y7j9Gx6bB+jpBWBk4HVgIGl42a2cor63wfGShpkZnOAzYFXm9TVcZxeSB7jGNPEJF4CXEww7lsBvwWubEDGH4Ft4t97EEJ/HMdxwswXKdWWJWkM42AzuxHAzJ41s+OBjRuQcSWwu6SBwOrAvXXKO45TIFq5GFarSBOu86FC7+izcSGrV4HUveBm9rCkMQRv8YZaZT2Dt+MUjzwOvqTxGI8AhgCHARsABwL/3aCcacCp1GlGewZvxykePdJjTKQJnw3sU6tsDS4C3jGzRyRt1GQdjuP0MkT2/YdpqBXgfR0xB2MlzOzLaYWY2SuE9V4dx3Hm0wZvMA21PMYup2ZOJqdNHLsNuK2rdTtdY9bsD+uWGbHwgLpl0gRvD93+zLpl/j3tsLplnN5JHvsYawV439IqITHQ+3QzOyruHw0MMbPJrZLhOE7PQ0CfHBrGrHIrfgh8WdKIjOQ5jtNDaOHyqa3TKSM5HxPSiR2RkTzHcXoIPdowSqrf4VSbc4C9JC1aQ4YnqnWcAhFCcfKXqDZNBu91JD0CPB3315B0VqOCzOxd4FJCPGS1Mh7H6DgFo6d6jGcC2wJvApjZP2hsSmCSnwH7Aws1eb3jOL2MPAZ4pzGMHWb2Ytmxec0IM7O3CEko9m/mesdxehch7VjPTCLxsqR1AJPUR9LhwFNdkHka4KPTjuMAwQil2bIkTRKJgwnN6dHAv4A/x2OpSQZ6m9m/gMGNXO+0njTB260iTfD20LUPqV9PioziTs8jh2GMqeZKvwHs3hUhkkYSRqVXIxj/3wPfMrOPulKv4zg9G0n0yWEK7zQZvM+nwpxpM5uURkBMWXYtcK6Z7SCpDyGm8WTgW42p6zhObyOHdjFVUzq52tFAYCfg5QZkbAJ8YGYXA5jZPElHAM9LOqG0XrXjOMWjNPiSN9I0pacm9yVdBtzcgIzPAQ+U1fmupJeAzwAPJ+r2RLWOUzByaBebGuxZHliugfKicvqyTsc9wNtxCkbK4O6sm9tp+hj/zXwD1gG8BRzTgIwZwM5ldS4CjAKebaAex3F6ISJ/LmNNjzEOnKwBLB63oWa2gpn9tgEZtwCDJX011tmHEMt4ifcvOk6xKa0rnTePsaZhNDMDrjOzeXGrmtG7Th07AbtKepoQHP4B8N1mFHYcp3eRR8OYZlT6PknjzOzBZoWY2cvAds1e7/R+0gRvexB470PQs+IYJfU1s4+BzwMHSnoWeJ84aGJm4xoRJGke8EiU+TiwrzelHafg9MA1X+4DxgE7tkjWHDNbE0DSr4GDgNNbVLfjOD2UVscxxnGM6cCrZrZtM3XUMowCMLPuGDm+HVi9G+p1HKcHURp8aTHfJLRKF2m2glqGcXFJR1Y7aWZNeXuS+gJbAX+qcM4DvB2nYLTSYYx5GbYhTDmuar/qUcsw9gGGQMuCjAZJeij+fTtwYXkBM5tCmEfN+PETGh4BdxynpyE60puYEZKmJ/anRJuR5GfAt4GFu6JVLcP4upn9oCuVl/FpH6PjOA4Er6sBj3GWmU2oWpe0LfCGmT0gaaOu6FW3j9FxHKfbaG2M4gbA9pK2JiS8WUTS5Wa2d6MV1Qrw3rRZ7RzHcdLSqqUNzOxYMxtpZmMIOWRvbcYoQg2PMa7P0jKSWbydrjFr9od1y7QiQ/dfnnyjbpmNV1miy3LSkiZ4+4J7n695/oB1l69bR5r7m4Yss6T3VPIa4J3JUgqSRkq6XtLTkp6TdHYL1ql2HKcX0B2rBJrZbc3GMEIGhjGRwft3ZrYSsBIwCPhJd8t2HCffiHwuhpWFvE4ZvIEjgK9K8ua14xQZhXVf0mxZkoVhrJjBG3iBkMH7UyRNkjRd0vSZs2ZmoJrjOO1GKbcsycIw1srgvQCewdtxikVpzZdWjEq3kiwM4wxggaDMmMF7SeDJDOQ7jpNjiuoxVsvgfbaZzclAvuM4OaY7RqW7SppEtV3CzEzSTsA5kr5HWCJhqpmd3N2yeyKtiqFrBVnGKLaKenGKO19wX906rjlgnVapU5cnXptdt8yqy3Rp2m/OyX5gJQ3dbhjh0wze2wNImghcIWm8mT1Q+0rHcXozAvoU1TCWZe9+HljDzN7OQrbjOPkmf2Yxu7jJOWa2ppmNJSy/+o2M5DqOk2cKHMdYzt3Asm2Q6zhOzijyzJdPiSPSmwLTqpz3AG/HKRhF9hhL2bvfBIYBN1cq5AHejlM8ihrHCPOzdy8H9Mf7GB3HieQxjjHTprSZvQMcBhwtqV+Wsh3HyR+hj1GptizJJFwniZn9XdI/CBl2L8taft7x5KbdS5rg7aFrH1K3TJqkuWno3cHbach+HnQasgrwHiLpOGBPYB7wCfBUFrIdx8k3ObSLmQV4rw9sC4wzsw8ljSD0NTqOU2BKTem8kVVTemnC0ocfApjZrIzkOo6TZ9owsJKGrAZfbgJGSXpK0i8kbZiRXMdxck5hR6XN7D1gPDAJmAlMlbRfeTkP8Hac4qGU/7Iks3AdM5sXV+46ATgE2LlCGQ/wdpwCETJ4p9uyJKvBl1WAT8zs6XhoTeDFLGQ7jpNvsvYG05DV4MsQ4CxJiwEfA88QmtWO4xScPA6+ZBXH+AAwMQtZjtNV0gRvZxkE3pspeqLa4YS1XwCWIgR5l0ZX1jGzj7LQw3GcvJH9wEoasvIY3yT0KyJpMvCemZ2ahWzHcXJMTuMYM58r7TiOkySHdjFfhlHSJOKgzKjRo9usjeM43U0I18mfaWzH0gZV8ThGxykeeUxUmyuP0XGcApI/h9ENo+M47aWwo9KO4zjVyHq6XxrakcF7cpbyZs3+sG4Zz5rtNEqa4O0nXptdt0wrMnj/5ck36pZ59u3365Y5YN3lu6xLU+TQMGYy+CJpjKRHy45NlnR0FvIdx8knYWAlf9l1vCntOE778ABvx3GczuTQLuYrjtET1TpOAWlRIKOkUZL+IulxSTMkfbNZlbIyjJbmuAd4O07RSNvDmMqv/Bg4ysw+C6wHfEPSas1olZVhfBMYWnZsGOCLYjlOwWnVmi9m9rqZPRj/ng08DizbjE5ZrvnyuqRNASQNA7YE7shCvuM4+SRtKzraxRGlrra4VU12LWkMsBZwbzN6ZTn48lXgHEmnxf0TzezZDOU7jpNDlH5YepaZTUhR3xDgGuBwM3u3GZ0yM4xm9hiwcVbySnjwttMorZoUkCZ4e8zBV9ct88K5u9Q8v/EqS9St479SfKZ20cpwHUn9CEbx12Z2bbP1dHtTWtJtkr5UduxwSb/obtmO4+SfVmXXUXA9LwQeN7PTu6JTFn2MVwC7lx3bPR53HKfINNjJWIcNgH2ATSQ9FLetm1Eri6b01cBJkgaY2YexU3QZfODFcRxal13HzO6gRfHi3e4xxvVe7iOMQkPwFqeaWafYRg/wdpxiIVoXrtNKsopjTDanqzajPcDbcYpHHjN4Z2UYfwdsKmkcMKgUhOk4jpNHy5jV8qnvSboNuAgfdHEcJ0EeM3hnmUTiCmAN4MoMZTqOk3M6lG7LkiwDvK8jnxmGHGcBWjUpYOcL7qtb5uLDv9gSWfVI85nqBbbP/aRaLpgukkOr0G0eo6QzJB2e2L9R0gWJ/dMkHdld8h3HyT95zeDdnU3pu4CJAJI6gBHA5xLnJwJ3dqN8x3HyTspQnd4UrnMn0TASDOKjwGxJQyUNAD4L/L0b5TuO0wPI4aB09/Uxmtlrkj6WNJpgIO8m5EZbH3gHeNjMPkpeE9MITQIYNXp0d6nmOE6eKFIfY6TkNZYM492J/bvKC3uAt+MUjZZm8G4Z3W0YS/2M/0VoSt9D8Bi9f9FxHKB4fYwQjN+2wFtmNs/M3gIWIxjHu7tZtuM4OSevc6W7O47xEcJo9G/Kjg0xM1/vxenVXHPAOpnIGbr2IXXL/Pv+s+uWqRfr2K+boqwLN/PFzOYRRqT3iuu8ABwB9Je0XHfKdhynZ5BHjzGLtGMvA+cCp8RDpwBTzOzF7pbtOE7+KVS4ThlnAA/EmTCfBw7NSK7jOHmmDd5gGrLKrjNX0reAPwFblMcvOo5TZPJnGbPMrrMV8DowtloBz+DtOMUir6PSmRhGSWsCmwPrAUdIWrpSOQ/wdpzikcc+xiyWTxVh8OVwM3sJ+ClwanfLdRynZ1BUj/FA4CUzuznu/wJYVdKGGch2HCfnSEq1ZUm3D76Y2RRgSmJ/HjC+u+X2VOolC4XWJVJ1egdpgreHbn9m/XqmHdYKdRomf0Mv2fUxStIdkrZKHPuKpD9lId9xnHySthnd26YEAmBmJukg4CpJfwH6ACczf61px3EKSh6nBGa55sujkv4P+A6wEHCpmT2blXzHcXJK/uxidoYxciLwIPARMCFj2Y7j5JAc2sVsDaOZvS9pKvCemXUaZfAM3o5TPPI4JTDLmS8lPolbJzzA23GKRj4zeGfdlHYcx/mU0pTAvOGG0XGctuKGETCzyVnL7El48HaxyCqg/6fHbVe3zFHTHqt5/uV3PuiyHpXIY7hOVgHeO0l6qGz7JBnw7ThOASl4gPd1wHWl/Tj6vBdwYxbyHcfJJ+3InJOGzJvSklYGvg9MNLOKo9OO4xSIHFrGTMN1JPUjrBh4dExBVn7eE9U6TsHIY7hO1nGMPwRmmNmVlU56HKPjFI889jFmZhglbQTsDNRfBNdxnMLQygzekraU9KSkZyQd06xOmfQxShoKXAzsaWazs5DpOE7PoFVJaCX1Ac4hLKPyCnC/pGlmVjsOqQJZDb4cBCwBnFt2E35sZlMz0sFxnJzR4pkv6wDPmNlzAJKuBHYAGjaMMrOWadVKJM0EXkwcGgHMqnNZTyuTJ11aVSZPuqQpkyddWlWmu+QsZ2Yt7fyPyapHpCw+EEhGmU+JKwSU6toF2NLMDoj7+wDrmlnj3Xdm1iM2YHpvK5MnXYr6mfKkS0/8THnagF2BCxL7+wBnNVNXO7LrOI7jdAevAKMS+yOB15qpyA2j4zi9hfuBlSQtL6k/sDswrZmKelJ2nSn1i/S4MnnSpVVl8qRLmjJ50qVVZbLUJTeY2ceSDiFMNe4DXGRmM5qpK7eDL47jOO3Cm9KO0wUk9ag1OCSNbLcOPQE3jE6PQimjgdOW66IuWwO3SFq2TrmaXVaS0oarIGl42rIVrl0CuFjSCElVf/u1zhWFQtwASeMlrSNpUAaylkpRpkv3PcUPbdm4VG3a+rr8HMTZTS2hjlHrk7KaWj/8tMZ1cI1zXwJOBfYxs1er3cOYTer4agZN0nLAT9J4cpJWBI6TtHyFcxtLWr9OFf2ARYC+ViWzlaTNgK/W06W3k1vDKGnJsv1qD97wWj9KSdsAFwGrAjXf7ClkjZe0Xh1Z0yRVDYKV9HlgP0lr1dHhM5IWrXB8BPCMpGHVrjWzV4Fhkm6tJSPWtxFwVqXP3IAB2QLctr7DAAANHUlEQVS4Of5fq9xoSQvVOD8yGpCKRkLS5sBlko6RtG2VMqdIuhC4SNI3q4jqX0vPWM/WwI8kjapwbgvgUsKMircAzOyTKvdrKDAMOLjKdzaE8FwuEeuu9ZvsA4wFNoxlk/I2JBq0anXE5+Iu4AuVyknaBPgdcGwWHneeyaVhlLQq8Lqk0yUdCOHBi+c6EuW2Bv4I/FLSSRXq2RD4OTDJzC41s2eqyFtJ0nqSNpE0tNJDHrONTwH+U6WOLYFjgO+b2cyYYq1SmbOAj4FORi9RbijwDYJ3sEjynJnNAg4F7qr0QijdHzPbAPhA0t+qyCh9vuHA7CoeRJ9Ytl70wiqEH+zRknasIm9J4CiCgehkHCXtAFwFXAhcLWlyDLkond8SOJnww14I2FnSumV1XAysBlwBXA8cIunHyXsYjdqVkk6Q9OUqum4L/Bi4zcxeLju3KXA2cGTU5b/jyw4zs/LnxszuBS4jeGqHlBvHOGp6G3CepEUqfQ8K4SeLmtlTwE+A0yRtZAuOnN5FfKaSdUj6oqTTJJ0qabWox0qlciV9Ex7w14H7rOijsu2OVq8SwT4KuBP4DmHo/VfAdsAiiTJbAncQ5kKuSXiDDyqr50jgm/HvvvF/lZXZBniQkGH8ZuBlYK1k2SjrTmCLuD8UWD5RxzDCkrA7xv0Vo87DEnVsCDxDmKKUlP+5xN+lsgK2IqRpOxEYUuEebQU8CwytcK4j8fcNwN8qlOkX/z+AxGyBxPkRwAvAsOT9q/J9jQDOAI4ArgV2raQTsDdwOsGwL5Q4tzHwFDAeWAxYGbiHYAg7Evd3u8TzMbV0v+OxzYGbymSOBm4FTk58j/cSXjonAucDnym7ZingL8Dacb8/MJjgxQ4E1iYkWYbwQvghwYhukKhjIrB7Wb3rEoza8VGvIYlzCwHnARtV+P5WBv4OXAksFY/tD1wC7EHIVrUBsDzhGV2mTO6qhKxW5wGnxGfw1uRzGO/d48D6cf8RYHyl30tRtrYrUFWx8EObSoi13IPg4t9OmCg+If5Qdopl1wFeJ2TW+CXzDcxZwEmVvmBgdYKxvQfYMHH8e8BLwBpxfzidjd7tyWvi8ZKBXR24BTi87PzhRCOdOPZTwlzUQ+J+yXh3xP93A+4jZDxftMI9aso4Mt/oLRrvwdSya0v3bzvgiVL98bsonVsdWL0kC/hf4IL4I7se2DmeWwlYpVRvrPMs4DCicQCOS9yDgfH/5eL9PD5xf2cQX47A5cD/JHTenBC3BqEvrXQvR8brPs+CxnUk4eVV/qIaCtwE/BfBEE4G/gz8lZAhaljy/sbP9wOCcZyY0PU5yl4QhOf0AoLhORXYIXHuR8DlFb7HvvGzvhz13Zow9a300rwo3u8/E5r1xwPbV3rmE9/bsVHexFj/oUTDTmgl3EKYc7yAHu22CVlubVegwhdX+uH1J74lgY3ig3YewUCeC3yZ8CZdg+DpnUjwJO4Broh1bBIfmNLbryPxQB8ffyjbxv2BCR1OiPIWTTzoJaN3M3BUFd23jHUek5DXyUjH/a0Ib/2JhGQZexOM1RLx/DIED+AX8SH+AQmPuayeJ0o/2LJzSeP4B+DPif3t4w90T4JnPpLgrQ2NP47hUf8FjG/8IZVeFq8DuxC8qL6EF9OXCAb9euDAWO4Ngpd2EPM9x+MJL4vB8fucXPr+gT7x79UJzcwlmO9FP01oyl5b9p2tCjwErJc4tlD8/zJgBTob1xti/WcQmvmLE4zqUYSWyivxOzqA4PFdQjQ6Zfd5JcIzcybR0EZdHwZ2K3uuD4zfxb6E6Wo/Ihj1voRndY9YbjSwcvx7BOH5/iHwPwSjeg/h91F6kSxPyI7/fwSP8GrC87NzQrYS+k4u6UvnF/KJhCz7pc+3KzCJxPPU27e2K1BRqfAjGACcFL/sJ5jvsa3E/B/pAoYoHhsSH7DhhCbKZEITZnyizG6E6UP7EozD8Hh8QKLMrcCExH650euTOL5xotzmUd+SUS09dJsSjOq4uN8P6B//Pp7gFW8HPEror7sF+EY8vxHBuzwNWLjC/dqBYLg7PbgsaByvJXpmcX+L+JnmAL8mvGgejrKnAYNjuXLj+HXg1XjtDwhe9m+ijnvHMvsRfrjbxHKHEvporyJ4Xr8ktAi+Ee9h+QusH+HlcA0LNrs3i/WVXiAlwyCCgT8DWLPsHvwxytqa+cb1rChzV4KxuY/QtF6E8AytD3yl7Jm4sPT5KtznVQme2OKJY1vHe7pb4tju8bP3JTSTv0t42f+R8OI/lfDcnk/wEEvP/b6E53Yo8DmCcf0EOC9R9xHAxfHvpQmDMSs0oG/JcH4HuDb+vRfhmVy13XYhUxvUbgVqKhf6cN4AvlejzObAk8Bicf9rhI7oheP+soSm6F/jQ3cSwXCNjefLf/SlvrfrS2XKZD2RkLVf/EEtX1Zuq6jTsMSxpJFeJ3F8D8KbfYW4X8nY9yF4YiclH+QymZ36IRPnSp7AscBxZee+ALxL8Er6AJ8leGhjKnymhwn9to8T+nU3JXi7wwnG5a8EA9sfWDjxHZT6sPoTvPp9CYbgzfijW5rKL7CvEPr7FqugywyicUwcXzreo6uA/yY0h68jeIX/y/wmfcm4Lpm8R8CIGvdwV2A6sGKNMv0qHPtSvEfHAUcTXshjE+dLL9iTCM/trHjvliIYpVeBg+M9vIb5L48lCS+kFRN1LUeF5ngj+sbjqwM/I3ib9wOrtdsWZL21XYEUX97X4o9mcI0yW8Uf2NeBv9HZoA0i9DFNjj/glStcnzSOXyV00i9RRdYj8WG9ncTgSVm5T7045r+JS0b6NoJn8yPCoMNqZdcu4HUmjle9Bynu44Aor9NDTvBsHk0aiip1lLy/NcqufYT5/YXL17j2Keb30Q0lYYDjvTmBYFxPIXiijyVl1bu/8fgwgld2F6GJflqNZ2ZGis+8NKHJP6P8uWrg3q8VP9OJwGfLziV1X7JcH2AcoaXxbcLL+jaiMaSshUDoCnmMsn7TJvQdHb/nJ8v1LcrWdgVSfEmrEvpNahoFYFvgo2qGKoWcpMG7q9aPIK0sKo8mDyKMIk4m9DetVEOfBbzOFtzLWiPLOxCafTX7kSp9D9E4Ps6CHnKljv+tonEcXqXuQQQP9qRojFZp9P4mzvUv26/UzVC1C6JMp20oG71u5VbpXpWdH0no5zwnGqwjyl8IpXoI3TLLdFGffoSuhpr3vzdvPSKJhKTBZlYxfrCZcjWu35bQD7eW1cnK0VVZKfXZgeBFTSCEyXXrlyVpiJm91+S1qXSN5SYTmoTdtq64JJV0SP5doVzTnzlLYlzsQEI/82lm9mSVcn3N7ONWyDOzuV2tp6fSIwxjlmRh8Bqhp/xwIb2uPekzOcXEDaPjOE4ZuZwS6DiO007cMDqO45ThhtFxHKcMN4yO4zhluGF0HMcpww1jL0PSPEkPSXpU0lWqkYU6RV0bSfp9/Ht7ScfUKLuYpK83IWOypKPTHi8rc4mkXRqQNUbSo43q6BQPN4y9jzlmtqaZjSXMzjkoeVKBhr93M5tmZqfUKLIYYUqm4/R43DD2bm4HPhM9pccl/YIwBW6UpC0k3S3pwehZDoGQKVvSE5LuIKR2Ix7fT9LZ8e8lJV0n6R9xm0iYC7xi9FZ/Gst9S9L9kh6WdGKiruMkPSnpz4REITWRdGCs5x+SrinzgjeTdLukp+LMJST1kfTThOz/6eqNdIqFG8ZeSlyOoDT/G4IButTM1gLeJ8yp3czMxhGyxhwpaSAh3dV2hDnL1Rb2OhP4q5mtQUhyMIOwrMOz0Vv9VlxCYCVCctY1gfExzf54QpKHtQiGd+0UH+daM1s7ynuckMG6xBhCdvRtCMsDDIzn3zGztWP9B6rCAlKOU416a3k4PY9Bkh6Kf99OyCG4DPCimd0Tj69HWBvlzrjkR3/gbkLCjufN7GkASZcTEpSWswlx4SUzmwe8o87rz2wRt7/H/SEEQ7kwcF1p2qWkaSk+01iFNX0Wi/XcmDj32zjn+mlJz8XPsAWweqL/cdEo+6kUshzHDWMvZI6ZrZk8EI3f+8lDwM1mtkdZuTWBVs0RFfBjM/tlmYzDm5BxCSFh6z8k7UdI3FuivC6Lsg81s6QBRdKYBuU6BcWb0sXkHmADSZ+BkDhDYf3jJ4DlFdYvhpBEtxK3ENKzlfrzFgFmE7zBEjcSVtAr9V0uq7Dg+9+AnSQNkrQwodlej4UJq0b2IyRvTbKrpI6o8wqEVG03ElYj7Bdlr6way7Y6TjnuMRYQC8u77gdcIWlAPHy8mT0laRLwB0mzCKswjq1QxTeBKZL2B+YBB5vZ3ZLujOEwf4z9jJ8F7o4e63uEZQEelDSVsD7Li4Tmfj2+R0gc/CKhzzRpgJ8kJLddEjjIzD6QdAGh7/FBBeEzgYrLujpOJTy7juM4ThnelHYcxynDDaPjOE4Zbhgdx3HKcMPoOI5ThhtGx3GcMtwwOo7jlOGG0XEcp4z/BwSnwffJeSefAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.33      0.10      0.15        10\n",
      "          1       0.67      0.80      0.73        10\n",
      "          2       0.44      0.40      0.42        10\n",
      "          3       0.46      0.60      0.52        10\n",
      "          4       0.57      0.80      0.67        10\n",
      "          5       0.60      0.60      0.60        10\n",
      "          6       1.00      1.00      1.00        10\n",
      "          7       0.83      1.00      0.91        10\n",
      "          8       0.82      0.90      0.86        10\n",
      "          9       1.00      0.80      0.89        10\n",
      "         10       0.91      1.00      0.95        10\n",
      "         11       0.71      1.00      0.83        10\n",
      "         12       1.00      0.70      0.82        10\n",
      "         13       1.00      0.90      0.95        10\n",
      "         14       0.77      1.00      0.87        10\n",
      "         15       1.00      1.00      1.00        10\n",
      "         16       0.80      0.40      0.53        10\n",
      "         17       0.86      0.60      0.71        10\n",
      "         18       0.83      1.00      0.91        10\n",
      "         19       0.91      1.00      0.95        10\n",
      "         20       0.25      0.20      0.22        10\n",
      "         21       0.57      0.80      0.67        10\n",
      "         22       0.00      0.00      0.00        10\n",
      "         23       0.77      1.00      0.87        10\n",
      "         24       0.50      0.90      0.64        10\n",
      "         25       0.83      0.50      0.62        10\n",
      "\n",
      "avg / total       0.71      0.73      0.70       260\n",
      "\n",
      "Precision : 0.7307692307692307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, pred)\n",
    "print('Plotting confusion matrix')\n",
    "\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cm, alphabet_array)\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_true, pred))\n",
    "print(\"Precision :\", metrics.accuracy_score(y_true, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
